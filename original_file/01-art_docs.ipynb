{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6157b9c7",
   "metadata": {},
   "source": [
    "# ART Docs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03293cea",
   "metadata": {},
   "source": [
    "ART (Agent Reinforcement Trainer) : An open-source framework for LLM reinforcement learning using GRPO\n",
    "\n",
    "\n",
    "GRPOë¥¼ ì‚¬ìš©í•˜ëŠ” LLM ê°•í™”í•™ìŠµì„ ìœ„í•œ open-source í”„ë ˆì„ì›Œí¬ì¸ ARTë¥¼ ì´ìš©í•˜ì—¬ \n",
    "\n",
    "ìì‹ ë§Œì˜ multi-turn agentsë¥¼ í›ˆë ¨ì‹œì¼œë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6c575",
   "metadata": {},
   "source": [
    "ART (Agent Reinforcement Trainer)ëŠ” Agentic LLMsì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ open-source training frameworkë¡œ\n",
    "\n",
    "**ê²½í—˜** ì„ í†µí•´ **ì„±ëŠ¥ê³¼ ì‹ ë¢°ì„±**ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ARTëŠ” GRPO (Group Relative Policy Optimization)ê³¼ ê°™ì€ ê°•í™”í•™ìŠµ ê¸°ìˆ ë“¤ì„ í¸ë¦¬í•˜ê²Œ wrapperë¡œ ì œê³µí•˜ì—¬ ìµœì†Œí•œì˜ í›ˆë ¨ ë¹„ìš©ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ì˜ ê·¹ì ì¸ í–¥ìƒì„ ì´ë£° ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb96b5ab",
   "metadata": {},
   "source": [
    "# Why ART? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885c8e3",
   "metadata": {},
   "source": [
    "- ARTëŠ” ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— RL trainingì„ ë„ì…í•˜ê¸° ìœ„í•œ í¸ë¦¬í•œ wrappersë“¤ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ê°œë°œìì˜ ì½”ë“œì™€ ìƒí˜¸ ì‘ìš©í•  í•„ìš”ê°€ ì—†ëŠ” ëª¨ë“ˆì‹ ì„œë¹„ìŠ¤ë¡œ í›ˆë ¨ ì„œë²„ë¥¼ ì¶”ìƒí™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **Train from anywhere.** ë…¸íŠ¸ë¶ì—ì„œ ART í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ART ì„œë²„ê°€ ì„ì‹œ GPU ì§€ì› í™˜ê²½ì„ ì‹œì‘í•˜ë„ë¡ í•˜ê±°ë‚˜ ë¡œì»¬ GPUì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "- W&B, Langfuse, OpenPipeì™€ ê°™ì€ í˜¸ìŠ¤íŒ… í”Œë«í¼ê³¼ì˜ í†µí•©ì€ ìœ ì—°í•œ ê´€ì°°ì„±ì„ ì œê³µí•˜ê³  ë””ë²„ê¹…ì„ ê°„ì†Œí™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ARTëŠ” ì§€ëŠ¥í˜• ê¸°ë³¸ê°’ì„ í†µí•´ ì‚¬ìš©ì ì •ì˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. íŠ¹ì • ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ í•™ìŠµ ë§¤ê°œë³€ìˆ˜ì™€ ì¶”ë¡  ì—”ì§„ êµ¬ì„±ì„ êµ¬ì„±í•˜ê±°ë‚˜, í•™ìŠµ íš¨ìœ¨ì„±ê³¼ ì•ˆì •ì„±ì„ ìœ„í•´ ìµœì í™”ëœ ê¸°ë³¸ê°’ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c57a4",
   "metadata": {},
   "source": [
    "# What is RL and when should I use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba4b62",
   "metadata": {},
   "source": [
    "RL (reinforcement learning)ì€ AI model ìì‹ ì˜ ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµí•  ìˆ˜ ìˆê²Œí•˜ëŠ” training ê¸°ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "RLì„ ê¸°ì¡´ LLMì— ì ìš©í•˜ëŠ” ê²ƒì€ ë‹¤ìŒê³¼ ê°™ì€ ê²ƒë“¤ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: \n",
    "- ì „ë°˜ì ì¸ agent ì‹ ë¢°ì„± í–¥ìƒ \n",
    "- QA ë˜ëŠ” ìƒì‚° ê³¼ì •ì—ì„œ ë°œê²¬ëœ íŠ¹ì • ì‹¤ìˆ˜ë¥¼ ìˆ˜ì •\n",
    "- ì‚¬ìš©ìì—ê²Œ ë°°í¬í•˜ê¸° ì „ì— agent ì„±ëŠ¥ì˜ ì‹ ë¢°ì„± êµ¬ì¶• \n",
    "\n",
    "Examples:\n",
    "- knowledge storeë¡œë¶€í„° searchí•˜ê³  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ deep research agent í›ˆë ¨ \n",
    "- ìƒˆë¡œìš´ training examplesë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ëª¨ë¸ behaviorì— ë°œìƒí•˜ëŠ” ì§œì¦ë‚˜ëŠ” ë²„ê·¸ í•´ê²°\n",
    "- ë§¤ë²ˆ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë”°ë¥´ëŠ” ì´ˆê³ ì† ìŒì„± ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f83ea",
   "metadata": {},
   "source": [
    "# What do I need in order to use RL?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059d735",
   "metadata": {},
   "source": [
    "\n",
    "### í•„ìš”í•œê²ƒ \n",
    "- âœ… í•˜ë‚˜ ë˜ëŠ” ê·¸ ì´ìƒì˜ LLMì„ ì‚¬ìš©í•  í”„ë¡œì íŠ¸\n",
    "- âœ… LLMì´ ì²˜ë¦¬í•´ì•¼ í•  ì‹œë‚˜ë¦¬ì˜¤ ì¢…ë¥˜ì— ëŒ€í•œ ì§€ì‹\n",
    "\n",
    "### í•„ìš”í•˜ì§€ ì•ŠëŠ” ê²ƒ \n",
    "- âŒ training dataset \n",
    "- âŒ ì™„ì„±ëœ reward (ë³´ìƒ) í•¨ìˆ˜ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f174d",
   "metadata": {},
   "source": [
    "# Tutorial: Implementing OpenPipe ART with Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0274f1c",
   "metadata": {},
   "source": [
    "í•´ë‹¹ íŠœí† ë¦¬ì–¼ì—ì„œ ìš°ë¦¬ëŠ” ARTë¥¼ simple agent taskì— ì ìš©í•˜ê³  Weights & Biases (W&B)ë¥¼ ì‚¬ìš©í•˜ì—¬ training progressë¥¼ ì¶”ì í•  ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "ìš°ë¦¬ agentì˜ taskëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§ê´€ì ì…ë‹ˆë‹¤: ê°„ë‹¨í•œ ê³±ì…ˆ ë¬¸ì œë¥¼ í‘¸ëŠ”ê²ƒ\n",
    "\n",
    "ì²˜ìŒì—ëŠ”, ìš°ë¦¬ì˜ language modelì€ ê³±ì…ˆì„ í•˜ëŠ”ë° ì‹¤ìˆ˜ë¥¼ í• ê²ƒì…ë‹ˆë‹¤, ê·¸ëŸ¬ë‚˜ ARTë¥¼ ì´ìš©í•˜ë©´, ì´ê²ƒì„ í›ˆë ¨ì‹œí‚¤ë©° ê°œì„ ì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” W&B Weaveì™€ W&B Modelsë“¤ë¡œ ì–´ë–»ê²Œ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•˜ëŠ”ì§€ ì•Œë ¤ì¤„ ê²ƒì´ë©°, trained modelì„ ë‹¤ë£¨ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤„ ê²ƒì…ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba62c9e",
   "metadata": {},
   "source": [
    "í•„ìˆ˜ì¡°ê±´: W&B ê³„ì •ì´ ìˆì–´ì•¼í•˜ê³  Pythonì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¹ì‹ ì€ ë‹¹ì‹ ì˜ local machoneì—ì„œ ê°•ë ¥í•œ GPUë¥¼ ì¤€ë¹„í•  í•„ìš” ì—†ìŠµë‹ˆë‹¤ - ìš°ë¦¬ëŠ” ë¡œì»¬ ì„¤ì •ì„ ì‚¬ìš©í•˜ì—¬ ì‹œì—°í•´ ë³´ê² ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ GPUê°€ ì—†ë‹¤ë©´ SkyPilot ë°±ì—”ë“œë¥¼ í†µí•´ ì›ê²© GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ ARTë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a66d9",
   "metadata": {},
   "source": [
    "## Step 1 : Install OpenPipe ART and set up W&B\n",
    "\n",
    "ë¨¼ì €, OpenPipe ART íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš” ê·¸ë¦¬ê³  ì‹¤í—˜ ì¶”ì ìœ¼ë¡œ ìœ„í•´ weights & Biasesì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤. \n",
    "ë‹¹ì‹ ì€ pipë¥¼ í†µí•´ openpipe-artë¥¼ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, W&B SDK (wandb)ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2cefafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openpipe-art wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d065ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q huggingface_hub transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9018329",
   "metadata": {},
   "source": [
    "Python script ë˜ëŠ” notebookì—ì„œ, W&Bë¥¼ ë¡œê·¸ì¸ í•˜ê³  ì´ˆê¸°í™” ì‹¤í–‰ì„ í•˜ì„¸ìš”: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d23d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede788d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyunew\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/khw/Workspace/llm/openpipe/ART_LangGraph/original_file/wandb/run-20250919_175534-jskix0nj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hyunew/my-agentic-task/runs/jskix0nj' target=\"_blank\">openpipe-art-demo</a></strong> to <a href='https://wandb.ai/hyunew/my-agentic-task' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hyunew/my-agentic-task' target=\"_blank\">https://wandb.ai/hyunew/my-agentic-task</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hyunew/my-agentic-task/runs/jskix0nj' target=\"_blank\">https://wandb.ai/hyunew/my-agentic-task/runs/jskix0nj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hyunew/my-agentic-task/runs/jskix0nj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x791a5a54d350>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "wandb.login()  # you'll be prompted to enter your W&B API key (from your W&B account page)\n",
    "wandb.init(project=\"my-agentic-task\", name=\"openpipe-art-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf479c3",
   "metadata": {},
   "source": [
    "`wandb.init` í˜¸ì¶œì€ í”„ë¡œì íŠ¸(ì´ ê²½ìš° \"my-agentic-task\")ì™€ ì¶”ì ì„ ìœ„í•œ ì‹¤í–‰ ì´ë¦„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ë¡œê¹…í•˜ëŠ” ëª¨ë“  ì§€í‘œê°€ W&B ëŒ€ì‹œë³´ë“œì— ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡ë©ë‹ˆë‹¤. (W&Bë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë ¤ë©´ ë¡œê·¸ì¸/ì´ˆê¸°í™” ë‹¨ê³„ë¥¼ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ARTëŠ” ì´ ë‹¨ê³„ ì—†ì´ë„ ì‘ë™í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ êµìœ¡ ê³¼ì •ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì–»ìœ¼ë ¤ë©´ ì´ ë‹¨ê³„ë¥¼ ì ê·¹ ê¶Œì¥í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa7ef7c",
   "metadata": {},
   "source": [
    "## Step 2 : Initialize the ART model and backendNext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c5d11",
   "metadata": {},
   "source": [
    "ìš°ë¦¬ëŠ” trainable modelê³¼ training backendë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. \n",
    "\n",
    "íŒŒì¸íŠœë‹ í•˜ê¸°ìœ„í•´ base modelì„ ì§€ì •í•´ì£¼ì„¸ìš”. OpenPipe ARTëŠ” ë§ì€ Hugging Face-compatible LLMsë“¤ì„ ì§€ì›í•©ë‹ˆë‹¤; ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ë°ëª¨ë¥¼ ìœ„í•´, (ìƒëŒ€ì ìœ¼ë¡œ lightweight modelì¸) Qwen 3B instruct modelê³¼ ê°™ì€ smaller modelì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ model ì´ë¦„ì„ ì§€ì–´ì£¼ê³  ë¡œê·¸ì¸ì„ ìœ„í•´ W&B projectë¥¼ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ë°±ì—”ë“œì˜ ê²½ìš°, ë¡œì»¬ ë°±ì—”ë“œ(ì‚¬ìš© ê°€ëŠ¥í•œ GPUê°€ ìˆë‹¤ëŠ” ê°€ì • í•˜ì—)ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ë¡œì»¬ì— GPUê°€ ì—†ë‹¤ë©´ SkyPilotBackendë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ê²© ë°±ì—”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b41c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khw/miniconda3/envs/openpipe/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-19 17:55:42 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khw/miniconda3/envs/openpipe/lib/python3.11/site-packages/art/__init__.py:10: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  import unsloth  # type: ignore # noqa: F401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 09-19 17:55:50 [__init__.py:235] Automatically detected platform cuda.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: Patching vLLM v1 graph capture\n",
      "Unsloth: Patching vLLM v0 graph capture\n",
      "==((====))==  Unsloth 2025.8.6: Fast Qwen2 patching. Transformers: 4.53.2. vLLM: 0.10.0.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 2. Max memory: 39.394 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 78.07%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.39 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 32768. Num Sequences = 320.\n",
      "Unsloth: vLLM's KV Cache can use up to 28.53 GB. Also swap space = 6 GB.\n",
      "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
      "INFO 09-19 17:56:14 [config.py:1604] Using max model len 32768\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
      "INFO 09-19 17:56:15 [llm_engine.py:228] Initializing a V0 LLM engine (v0.10.0) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, num_scheduler_steps=16, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":true,\"trace.graph_diagram\":false,\"compile_threads\":32,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":320,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 09-19 17:56:17 [cuda.py:398] Using Flash Attention backend.\n",
      "INFO 09-19 17:56:17 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 09-19 17:56:17 [model_runner.py:1083] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n",
      "INFO 09-19 17:56:18 [bitsandbytes_loader.py:733] Loading weights with BitsAndBytes quantization. May take a while ...\n",
      "INFO 09-19 17:56:19 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "INFO 09-19 17:56:20 [weight_utils.py:349] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 15.50it/s]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.04it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.04it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-19 17:56:21 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "INFO 09-19 17:56:22 [model_runner.py:1115] Model loading took 2.2562 GiB and 3.414136 seconds\n",
      "INFO 09-19 17:56:26 [worker.py:295] Memory profiling takes 3.73 seconds\n",
      "INFO 09-19 17:56:26 [worker.py:295] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.78) = 30.75GiB\n",
      "INFO 09-19 17:56:26 [worker.py:295] model weights take 2.26GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 2.69GiB; the rest of the memory reserved for KV Cache is 25.71GiB.\n",
      "INFO 09-19 17:56:26 [executor_base.py:113] # cuda blocks: 46811, # CPU blocks: 10922\n",
      "INFO 09-19 17:56:26 [executor_base.py:118] Maximum concurrency for 32768 tokens per request: 22.86x\n",
      "INFO 09-19 17:56:31 [vllm_utils.py:671] Unsloth: Running patched vLLM v0 `capture_model`.\n",
      "INFO 09-19 17:56:31 [model_runner.py:1385] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:16<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-19 17:56:48 [model_runner.py:1537] Graph capturing finished in 17 secs, took 5.75 GiB\n",
      "INFO 09-19 17:56:48 [vllm_utils.py:678] Unsloth: Patched vLLM v0 graph capture finished in 17 secs.\n",
      "INFO 09-19 17:56:49 [llm_engine.py:424] init engine (profile, create kv cache, warmup model) took 27.12 seconds\n",
      "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'pre_feedforward_layernorm', 'q_norm', 'k_norm']\n",
      "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'pre_feedforward_layernorm', 'q_norm', 'k_norm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.6 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "import art  # import the OpenPipe ART library\n",
    "from art.local import LocalBackend\n",
    "\n",
    "model_name = \"agent-001\"\n",
    "project_name = \"my-agentic-task\"\n",
    "base_model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "\n",
    "# Create a trainable model instance\n",
    "model = art.TrainableModel(\n",
    "    name=model_name,                # an arbitrary name for your model (used for logging)\n",
    "    project=project_name,       # W&B project name for grouping runs\n",
    "    base_model=base_model_name,    # base model to fine-tune (needs to be a model identifier or path)\n",
    ")\n",
    "\n",
    "\n",
    "# Set up the training backend\n",
    "backend = LocalBackend()  # use local GPU; ensure your machine has a GPU and drivers if using this\n",
    "\n",
    "\n",
    "# If no local GPU, you can use SkyPilotBackend as follows:\n",
    "# from art.skypilot import SkyPilotBackend\n",
    "# backend = await SkyPilotBackend.initialize_cluster(cluster_name=\"art-demo\", gpu=\"A10\")  \n",
    "# (The above would asynchronously provision a remote GPU machine, e.g., with an Nvidia A10 card.)\n",
    "\n",
    "\n",
    "# Register the model with the backend (prepare the backend server)\n",
    "await model.register(backend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e142a3d",
   "metadata": {},
   "source": [
    "- `TrainableModel` ëŠ” modelì„ ì…‹ì—…í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” `base_model=\"Qwen/Qwen2.5-3B` ë¥¼ ì˜ˆì œë¡œ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ART ì‹œìŠ¤í…œì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤ (Hugging Face Hubì˜ ê³µê°œ ëª¨ë¸ì¸ ê²½ìš° ARTì—ì„œ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤). ë˜í•œ ë‹¹ì‹ ì´ fine-tuningí•˜ê¸° ì›í•˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ë¡œ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "- trainingì„ ìœ„í•´ local server processë¥¼ ëŸ°ì¹­í•  `LocalBackend` ë¥¼ ë§Œë“­ë‹ˆë‹¤. ` await model.register(backend)` ë¥¼ í˜¸ì¶œí•˜ë©´, ARTëŠ” ë°±ì•¤ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ë°±ì•¤ë“œì˜ vLLM ì„œë²„ì—ì„œ ëª¨ë¸ì„ ë¡œë”©í•˜ê³  í›ˆë ¨í•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤). ì´ stepì€ model weightsë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ê¸° ë•Œë¬¸ì—, ì´ˆê¸°ì— ì‹œê°„ì„ ì¡°ê¸ˆ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "\n",
    "- Note: `await` ëŠ” `register`ê°€ asynchronous operation ì„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  top-level `await`ë¥¼ ì§€ì›í•˜ëŠ” ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œëŠ” ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ Python scriptì—ì„œëŠ” `asyncio` event loop ë‚´ì—ì„œ ì´ë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ê°„ë‹¨í•˜ê²Œ, ì´ ì½”ë“œëŠ” notebook ì•ˆì— ë˜ëŠ” async context ì•ˆì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. (ë§Œì•½, scriptë¥¼ ì‚¬ìš©í•˜ë©´, ì´ëŸ¬í•œ í˜¸ì¶œì„ `async def main()`ìœ¼ë¡œ wrappingí•˜ê³  `asyncio.run(main())`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048c580",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì€ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ë¡ ê³¼ í•™ìŠµì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°±ì—”ë“œì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ê°•í™” í•™ìŠµ ë£¨í”„ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec909a2",
   "metadata": {},
   "source": [
    "## Step 3: Define the task and the reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305a5fe",
   "metadata": {},
   "source": [
    "í•´ë‹¹ íŠœí† ë¦¬ì–¼ì—ì„œ ìš°ë¦¬ì˜ taskëŠ” ê°„ë‹¨í•©ë‹ˆë‹¤: 2ê°œì˜ ìˆ˜ê°€ ì£¼ì–´ì§€ë©´, agent (model)ì€ ì´ ë‘ ìˆ˜ì˜ ê³±ì…ˆì„ ì¶œë ¥í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í•´ë‹¹ ëª¨ë¸ì— ëŒ€í•´ question-answer interactionìœ¼ë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ë“¤ì–´, ìš°ë¦¬ëŠ” \"What is 12*13?\" ì„ ì œì‹œí•˜ë©´, ëŒ€ë‹µìœ¼ë¡œ \"156\" ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ë§Œì•½ ëª¨ë¸ì˜ ëŒ€ë‹µì´ ì˜³ë‹¤ë©´, ìš°ë¦¬ëŠ” positive rewardë¥¼ ì£¼ê³ , ë§Œì¼ í‹€ë ¸ë‹¤ë©´, ìš°ë¦¬ëŠ” negative rewardë¥¼ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼, ëª¨ë¸ì€ ë” ë§ì€ ë³´ìƒì„ ë°›ê¸° ìœ„í•´ ì¶œë ¥ì„ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤(ì¦‰, ë³´ì´ëŠ” ìˆ«ì ë²”ìœ„ì— ë§ê²Œ ì˜¬ë°”ë¥´ê²Œ ê³±í•˜ëŠ” ë²•ì„ ë°°ì›Œì•¼ í•©ë‹ˆë‹¤).\n",
    "\n",
    "ìš°ë¦¬ëŠ” rollout functionì„ ì •ì˜í•´ì•¼í•©ë‹ˆë‹¤: ì´ functionì€ agentì˜ í•œ episode/interactionì„ ì‹¤í–‰í•˜ê³  `Trajectory` (ë©”ì‹œì§€ ì‹œí€€ìŠ¤ ê·¸ë¦¬ê³  final reward) ë¥¼ return í•©ë‹ˆë‹¤. \n",
    "ARTì—ì„œ, ì¼ë°˜ì ìœ¼ë¡œ `model.openai_clinet()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ê³¼ interactí•  ìˆ˜ ìˆëŠ” **rollout function**ì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” ê³±ì…ˆ ì‘ì—…ì— ëŒ€í•œ ë‹¨ìˆœí™”ëœ rollout functionì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16372cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "# Define one scenario rollout for the multiplication task\n",
    "async def rollout(model: art.TrainableModel) -> art.Trajectory:\n",
    "    # Step 1: Prepare a random multiplication problem\n",
    "    a = random.randint(1, 20)\n",
    "    b = random.randint(1, 20)\n",
    "    question = f\"What is {a} * {b}?\"\n",
    "    \n",
    "    # Step 2: Get the model's answer\n",
    "    openai_client = model.openai_client()\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    \n",
    "    completion = await openai_client.chat.completions.create(\n",
    "        model=model.name,\n",
    "        messages=messages,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    answer = completion.choices[0].message.content.strip()\n",
    "\n",
    "    # Step 3: Calculate reward\n",
    "    correct_answer = str(a * b)\n",
    "    reward_value = 1.0 if answer == correct_answer else -1.0\n",
    "\n",
    "    # Step 4: ì˜¬ë°”ë¥¸ Trajectory ìƒì„±\n",
    "    trajectory = art.Trajectory(\n",
    "        messages_and_choices=[  # messages ëŒ€ì‹  messages_and_choices ì‚¬ìš©\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ],\n",
    "        reward=reward_value\n",
    "    )\n",
    "    \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50057f16",
   "metadata": {},
   "source": [
    "ìœ„ rollout ì½”ë“œë¥¼ íŒŒí•´ì³ë´…ì‹œë‹¤.\n",
    "\n",
    "- ê³±ì…ˆ ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•´ `a`ì™€ `b` 2ê°œì˜ ìˆ«ìë¥¼ ëœë¤ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- ì´ ìˆ«ìë“¤ì˜ ê³±ì„ ë¬»ëŠ” user messageë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. (ë” ë³µì¡í•œ agentì—ì„œëŠ” instructionì„ í¬í•¨í•œ system messageë„ ì¶”ê°€í•  ìˆ˜ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ êµ¬ì„±í•©ë‹ˆë‹¤)\n",
    "- ìš°ë¦¬ì˜ ëª¨ë¸ì—ì„œ `openai_client`ë¥¼ ê°€ì ¸ì˜¤ê³ , `chat.completions.create` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì‘ë‹µì„ ê°€ì ¸ì˜µë‹ˆë‹¤. `model=model.name`ì„ ì§€ì •í•˜ì—¬ ìš”ì²­ì´ ë°±ì—”ë“œì— ë“±ë¡í•œ fine-tuning ì¸ìŠ¤í„´ìŠ¤ë¡œ ì „ë‹¬ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "- ëª¨ë¸ì˜ ëŒ€ë‹µì´ ìº¡ì³ë©ë‹ˆë‹¤. formatting ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ í•´ë‹¹ ë‹µë³€ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "- ê·¸ëŸ°ë‹¤ìŒ rewardë¥¼ ê²°ì •í•©ë‹ˆë‹¤: ë§Œì¼ ëŒ€ë‹µì´ ì •ë‹µì´ë©´, reward = +1, ì•„ë‹ˆë©´, -1ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤. (ìš°ë¦¬ëŠ” ê°„ë‹¨í•œ reward ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤; ë” ë³µì¡í•œ taskëŠ” ë” ë³µì¡í•œ scoringì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
    "- ìš°ë¦¬ëŠ” `art.Trajectory` objectë¥¼ ìƒì„±í•˜ì—¬ interactionì„ ê¸°ë¡í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” user questionê³¼ assistant's answerë¥¼ ëª¨ë‘ messagesì— í¬í•¨í•©ë‹ˆë‹¤. ê·¸ëŸ°ë‹¤ìŒ, ìš°ë¦¬ëŠ” trajectoryì— rewardë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "- trajectoryê°€ returnë˜ì–´, í•´ë‹¹ í™˜ê²½ì—ì„œ agentì˜ í•œ rolloutì´ ìº¡ìŠí™”ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a009031",
   "metadata": {},
   "source": [
    "## Step 4: Run training iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe41b7b",
   "metadata": {},
   "source": [
    "ì •ì˜ëœ rollout functionê³¼ í•¨ê¼, ì—¬ëŸ¬ iterationsë¥¼ í†µí•´ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ê°•í™” í•™ìŠµì˜ ê´€ì ì—ì„œ ë³´ë©´, ìš°ë¦¬ëŠ” ì¼ë ¨ì˜ ì—í”¼ì†Œë“œë¥¼ ì§„í–‰í•˜ê³ , ê° ì—í”¼ì†Œë“œ ë°°ì¹˜ê°€ ëë‚  ë•Œë§ˆë‹¤ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë°ëª¨ë¥¼ ìœ„í•´, ìš°ë¦¬ëŠ” 50ë²ˆì˜ training setipì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ê° ìŠ¤í…ì—ì„œ, ìš°ë¦¬ëŠ” ì—¬ëŸ¬ ê³±ì…ˆ ë¬¸ì œë“¤ì„ agentì—ê²Œ ì œê³µí•©ë‹ˆë‹¤ (update ì „ì— ì¶©ë¶„í•œ ê²½í—˜ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´)\n",
    "\n",
    "\n",
    "OpenPipe ARTë¥¼ ì‚¬ìš©í•˜ì—¬, modelì„ training í•˜ëŠ” ê²ƒì€ \n",
    "\n",
    "\n",
    "OpenPipe ARTë¥¼ ì‚¬ìš©í•˜ë©´ ë¡¤ì•„ì›ƒì—ì„œ train methodë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒë§Œí¼ ì‰½ê²Œ ëª¨ë¸ì„ training í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì˜ˆë¥¼ ë“¤ì–´, ARTë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ ë¡¤ì•„ì›ƒì„ ê·¸ë£¹í™”í•˜ê³  ë‚´ë¶€ì ìœ¼ë¡œ trainingì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” trainingì— ëŒ€í•œ pseudo code ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92eb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a76d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:32<00:00,  1.55it/s, Step=49, Avg_Reward=-1.000, Last_Rewards=['-1.0', '-1.0', '-1.0']]\n"
     ]
    }
   ],
   "source": [
    "# Train the model for a certain number of steps\n",
    "training_steps = 50\n",
    "rollouts_per_step = 8  # how many problems to attempt per step (parallel rollouts)\n",
    "\n",
    "pbar = tqdm(range(training_steps), total=training_steps, desc=\"Training\")\n",
    "\n",
    "for step in pbar:\n",
    "    # Collect trajectories from multiple parallel rollouts\n",
    "    trajectories = [rollout(model) for _ in range(rollouts_per_step)]\n",
    "    # Wait for all the asynchronous rollouts to finish\n",
    "    trajectories = await asyncio.gather(*trajectories)\n",
    "\n",
    "    # Log the mean reward of this batch for monitoring\n",
    "    avg_reward = sum(t.reward for t in trajectories) / len(trajectories)\n",
    "    wandb.log({\"step\": step, \"average_reward\": avg_reward})\n",
    "    \n",
    "    # í”„ë¡œê·¸ë ˆìŠ¤ë°”ì— ì‹¤ì‹œê°„ ì •ë³´ í‘œì‹œ\n",
    "    pbar.set_postfix({\n",
    "        'Step': step,\n",
    "        'Avg_Reward': f'{avg_reward:.3f}',\n",
    "        'Last_Rewards': [f'{t.reward:.1f}' for t in trajectories[-3:]]  # ë§ˆì§€ë§‰ 3ê°œë§Œ í‘œì‹œ\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2decfb",
   "metadata": {},
   "source": [
    "ìœ„ ì½”ë“œì—ì„œ, ìš°ë¦°ëŠ” `rollout(model)` ì„ ë™ì‹œì— 8ë²ˆ ì‹¤í–‰ì‹œì¼œ ê²½í—˜ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ (async contextì¸ ê²½ìš° `asyncio.gather`ë¥¼ ì‚¬ìš©í•˜ì—¬) ëª¨ë“  í•­ëª©ì„ await í•˜ì—¬ trajectories resultsì˜ listë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ì´ëŸ° trajectoriesëŠ” agentì˜ interactonsê³¼ rewardë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì´ê²ƒë“¤ì´ ìˆ˜ì§‘ë˜ë©´, ARTì˜ backendëŠ” ë‚´ë¶€ì ìœ¼ë¡œ trainingì´ ì—…ë°ì´íŠ¸ ë ê²ƒì…ë‹ˆë‹¤. (ARTëŠ” ë‚´ë¶€ì ìœ¼ë¡œ trajectoriesë¥¼ ê·¸ë£¹í™”í•˜ê³  GRPO ìµœì í™” ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì˜ policyë¥¼ ê°œì„ í•©ë‹ˆë‹¤.)\n",
    "\n",
    "ìš°ë¦¬ëŠ” ë˜í•œ rolloutsì˜ batchì— ëŒ€í•´ reward í‰ê· ì„ W&Bì— ë¡œê¹…í•©ë‹ˆë‹¤. ì´ê²ƒì€ training progressì™€ ê°™ì€ ê²ƒì„ ë³´ê¸°ì— ìœ ìš©í•œ ì§€í‘œì…ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ë˜í•œ í•´ë‹¹ rolloutsì˜ batchì— ëŒ€í•œ í‰ê·  rewardë¥¼ W&Bì— ë¡œê¹…í•©ë‹ˆë‹¤. ì´ëŠ” ê´€ì°°í•˜ê¸° ìœ ìš©í•œ ì§€í‘œì…ë‹ˆë‹¤. í›ˆë ¨ì´ ì§„í–‰ë¨ì— ë”°ë¼ Agentê°€ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµí•˜ê³  ìˆë‹¤ë©´ í‰ê·  rewardê°€ 1.0ì— ê°€ê¹Œì›Œì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ìš°ë¦¬ì˜ ê³±ì…ˆ task ì˜ˆì‹œì—ì„œ, í‰ê·  reward 1.0ì€ ì—ì´ì „íŠ¸ê°€ í•´ë‹¹ ë°°ì¹˜ì—ì„œ ëª¨ë“  ë‹µì„ ì˜¬ë°”ë¥´ê²Œ ë§ì·„ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f5f7c",
   "metadata": {},
   "source": [
    "## Step 5: Monitor training with Weave and W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74040ab",
   "metadata": {},
   "source": [
    "training loopë¥¼ ì‹¤í–‰í•˜ë©´, ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§€í‘œë¥¼ ê´€ì¸¡í•˜ê¸° ìœ„í•´ Weight & Biases project pageë¡œ ì´ë™ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì€ ê° stepë³„ë¡œ ë¡œê¹…ëœ training curveë¥¼ í¬í•¨í•´ `average_reward` ì§€í‘œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì¼ ë‹¹ì‹ ì´ ARTì—ì„œ ëª¨ë¸ì˜ `project` ì™€ `name` ì„ ì œëŒ€ë¡œ ì„¤ì •í•˜ì˜€ë‹¤ë©´, ARTëŠ” ì•„ë§ˆ (loss ë˜ëŠ” policy entropyì™€ ê°™ì€) ì¶”ê°€ì ì¸ ì§€í‘œë¥¼ ìë™ìœ¼ë¡œ W&Bì— ë¡œê¹…í•  ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "\n",
    "ì´ë•Œ W&B Weaveê°€ ìœ ìš©í•©ë‹ˆë‹¤. Weaveë¥¼ ì‚¬ìš©í•˜ë©´ ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ì„ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆëŠ” interactive ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¨ìˆœíˆ reward curveë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒë¿ ì•„ë‹ˆë¼, ì§ˆë¬¸ê³¼ ë‹µë³€ ìƒ˜í”Œì„ í•¨ê»˜ í‘œì‹œí•˜ì—¬ ëª¨ë¸ ì¶œë ¥ì´ ì–´ë–»ê²Œ ê°œì„ ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” Weave íŒ¨ë„ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜, ê³±ì…ˆ ë¬¸ì œì™€ ì—ì´ì „íŠ¸ê°€ ì„œë¡œ ë‹¤ë¥¸ í•™ìŠµ ë‹¨ê³„ì—ì„œ ë‚¸ ë‹µë³€ì„ í‘œ í˜•íƒœë¡œ ë‚˜ì—´í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë©°, ì´ëŠ” ì •ì„±ì  í‰ê°€ì— ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. Weaveì˜ ê°•ì ì€ í”Œë¡¯, í…ìŠ¤íŠ¸, ì‹¬ì§€ì–´ ëª¨ë¸ ì¿¼ë¦¬ê¹Œì§€ í•œ ê³µê°„ì— ê²°í•©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ìœ¼ë¡œ, AI ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶„ì„ì„ ìœ„í•œ ìœ ì—°í•œ íˆ´í‚·ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ Weights & Biasesì—ëŠ” Models(ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë° ì•„í‹°íŒ©íŠ¸)ë¼ëŠ” ê¸°ëŠ¥ë„ ìˆìŠµë‹ˆë‹¤. í•™ìŠµì´ ëë‚˜ë©´, ì˜ˆë¥¼ ë“¤ì–´ ARTê°€ í•™ìŠµí•œ LoRA ì–´ëŒ‘í„°ì™€ ê°™ì€ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ì‹¶ì„ ê²ƒì…ë‹ˆë‹¤. W&Bë¥¼ ì‚¬ìš©í•˜ë©´ ì´ëŸ¬í•œ ê²°ê³¼ë¬¼ì„ ë²„ì €ë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "394290cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./.art/my-agentic-task/models)... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done. 0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact multiplication-agent-lora>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training is done, save the LoRA weights \n",
    "final_lora_dir = f\"./.art/{project_name}/models\"  # hypothetical path where ART stored LoRA checkpoints\n",
    "# Log the fine-tuned model as a W&B artifact for versioning\n",
    "artifact = wandb.Artifact(name=\"multiplication-agent-lora\", type=\"model\")\n",
    "artifact.add_dir(final_lora_dir)\n",
    "wandb.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed7e72",
   "metadata": {},
   "source": [
    "ì•„í‹°íŒ©íŠ¸ë¥¼ ê¸°ë¡í•¨ìœ¼ë¡œì¨, í•™ìŠµëœ ì—ì´ì „íŠ¸ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ W&Bì— ì˜êµ¬ì ìœ¼ë¡œ ë³´ê´€í•  ìˆ˜ ìˆê³ , ì´í›„ì— ì´ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ë¹„êµí•˜ê±°ë‚˜, ì‹¬ì§€ì–´ ë°°í¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. W&B Models(ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬)ëŠ” ì´ëŸ¬í•œ ì•„í‹°íŒ©íŠ¸ì™€ ê·¸ ê³„ë³´(lineage)ë¥¼ ì¶”ì í•  ìˆ˜ ìˆì–´, ì–´ë–¤ í•™ìŠµ ì‹¤í–‰(run)ì—ì„œ ì–´ë–¤ ëª¨ë¸ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ë¥¼ ëª…í™•íˆ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315388c8",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the trained agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ceda0",
   "metadata": {},
   "source": [
    "50ë²ˆì˜ stepsë¥¼ í›ˆë ¨ì‹œí‚¨ ì´í›„ë¼ë©´, ì´ì œ agentê°€ ì–¼ë§ˆë‚˜ ì˜ í•™ìŠµ ë˜ì—ˆëŠ”ì§€ test í•  ì‹œê°„ì…ë‹ˆë‹¤.\n",
    "\n",
    "`model.openai_client()`ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ ê³±ì…ˆ ë¬¸ì œì— ë‹µí•˜ê³  ì •ë‹µì¸ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ìƒì ìœ¼ë¡œëŠ” ì´ ëª¨ë¸ì´ ì²˜ìŒë³´ë‹¤ ì´ ì‘ì—…ì—ì„œ í›¨ì”¬ ë” ì•ˆì •ì ì´ë¼ëŠ” ê²ƒì„ ì•Œê²Œ ë  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "í›ˆë ¨ í›„, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´, ì•„ë˜ ëª‡ê°€ì§€ ìƒ˜í”Œ ì¿¼ë¦¬ë¥¼ ì‹œë„í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e1270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = model.openai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3941825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is 7 * 8? -> A: 7 * 8 equals 56.\n",
      "Q: What is 15 * 14? -> A: 15 * 14 equals 210.\n",
      "Q: What is 3 * 19? -> A: 3 times 19 equals 57.\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\"What is 7 * 8?\", \"What is 15 * 14?\", \"What is 3 * 19?\"]\n",
    "\n",
    "\n",
    "for q in test_questions:\n",
    "    completion = await openai_client.chat.completions.create(\n",
    "        model=model.name,\n",
    "        messages=[{\"role\": \"user\", \"content\": q}]\n",
    "    )\n",
    "    answer = completion.choices[0].message.content.strip()\n",
    "    print(f\"Q: {q} -> A: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb87449",
   "metadata": {},
   "source": [
    "í•™ìŠµì´ ì œëŒ€ë¡œ ì´ë£¨ì–´ì¡Œë‹¤ë©´, ìœ„ì˜ ì¿¼ë¦¬ì— ëŒ€í•œ ë‹µë³€ì´ ì •í™•íˆ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤(ì˜ˆ: `56, 210, 57`). ë§Œì•½ ì¼ë¶€ê°€ í‹€ë¦¬ê±°ë‚˜ ì •í™•ë„ë¥¼ ë” ë†’ì´ê³  ì‹¶ë‹¤ë©´, í•™ìŠµ ìŠ¤í…ì„ ë” ëŠ˜ë¦¬ê±°ë‚˜ ì „ëµì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì˜ˆ: ìˆ«ìì˜ ë²”ìœ„ë¥¼ ë„“íˆê±°ë‚˜ ë³´ìƒ ì²´ê³„ë¥¼ ë°”ê¾¸ëŠ” ë°©ë²•).\n",
    "\n",
    "ë‹¤ë¥¸ í™œìš© ì‚¬ë¡€: ì§€ê¸ˆ ì‚´í´ë³¸ ì˜ˆì‹œëŠ” ë§¤ìš° ë‹¨ìˆœí•˜ì§€ë§Œ, OpenPipe ARTëŠ” ë‹¤ì–‘í•œ ì—ì´ì „íŠ¸ ì‘ì—…ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜í•™ ë¬¸ì œ ëŒ€ì‹  â€œí™˜ê²½(environment)â€ì„ `ê²Œì„(ì˜ˆ: 2048, í‹±íƒí† â€”ARTë¡œ ì´ë¯¸ ì‹œì—°ëœ ë°” ìˆìŒ)`, `ì§€ì‹ ê²€ìƒ‰ ì‘ì—…(ì—ì´ì „íŠ¸ê°€ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì •ë³´ë¥¼ ì°¾ê³  ìš”ì•½)`, í˜¹ì€ `ëŒ€í™” ì›Œí¬í”Œë¡œìš°(ì—ì´ì „íŠ¸ê°€ ê¸´ ëŒ€í™” ì†ì—ì„œ ì§€ì‹œë¥¼ ë”°ë¼ì•¼ í•˜ëŠ” ê²½ìš°)`ë¡œ ì„¤ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê³¼ì •ì€ ëŒ€ë¶€ë¶„ ë™ì¼í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•´ì•¼ í•  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. ART í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•´ í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì—ì´ì „íŠ¸ì™€ ìƒí˜¸ì‘ìš©í•˜ê³ , ë§ˆì§€ë§‰ì— ë³´ìƒì„ ë¶€ì—¬í•˜ëŠ” rollout í•¨ìˆ˜ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. ì—¬ëŸ¬ ë²ˆì˜ rolloutì„ ì‹¤í–‰í•´ ARTê°€ ëª¨ë¸ì˜ ë™ì‘ì„ ìµœì í™”í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë³´ìƒ í•¨ìˆ˜ì™€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¡°ì •í•¨ìœ¼ë¡œì¨, ê²Œì„ í”Œë ˆì´ë¶€í„° ëŒ€í™” ì† ì‚¬ì‹¤ì„±ì´ë‚˜ ì•ˆì „ì„± ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ê¹Œì§€ ë‹¤ì–‘í•œ ê¸°ìˆ ì„ ì—ì´ì „íŠ¸ì—ê²Œ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ëª¨ë“  ê³¼ì •ì—ì„œ W&BëŠ” ì‹¤í—˜ ì¶”ì ì— ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ë¥¸ ë³´ìƒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ í•™ìŠµì´ ë” ë¹¨ë¼ì¡ŒëŠ”ì§€ ë¹„êµí•  ìˆ˜ ìˆê³ , ì„±ëŠ¥ì„ ì‹œê°í™”í•˜ë©°, ìµœìƒì˜ ëª¨ë¸ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. OpenPipe ARTì™€ W&Bì˜ í†µí•© ë•ë¶„ì— í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•˜ê±°ë‚˜ ì—ì´ì „íŠ¸ì˜ ë™ì‘ì„ ë””ë²„ê¹…í•  ë•Œ ë§¤ìš° í’ë¶€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f88b7a",
   "metadata": {},
   "source": [
    "## Step 7: ëª¨ë¸ ì €ì¥ ë° í—ˆê¹…í˜ì´ìŠ¤ì— ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. í—ˆê¹…í˜ì´ìŠ¤ì— ì—…ë¡œë“œí•˜ê¸° ìœ„í•œ ì„¤ì • (.env íŒŒì¼ ì‚¬ìš©)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ë“¤ì„ ë¡œë“œ\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "HF_USERNAME = os.environ.get(\"HF_USERNAME\")\n",
    "\n",
    "repo_id = f\"{HF_USERNAME}/{model.name}-ART\"\n",
    "\n",
    "print(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d49bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_450660/2341394760.py:7: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth import FastLanguageModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Saving trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.6: Fast Qwen2 patching. Transformers: 4.53.2. vLLM: 0.10.0.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 2. Max memory: 39.394 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.6 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.4MB / 11.4MB,  205kB/s  \n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  329kB /  329kB,  205kB/s  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /home/khw/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00002.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Downloading safetensors index for unsloth/qwen2.5-3b-instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.97GB / 3.97GB,  108MB/s  t/s]\n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  275MB /  275MB,  693kB/s  \n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.20GB / 2.20GB,  133MB/s  , 163.40s/it]\n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.44MB / 7.44MB,  744kB/s  \n",
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [04:06<00:00, 123.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model successfully uploaded to: https://huggingface.co/HueyWoo/agent-001\n"
     ]
    }
   ],
   "source": [
    "## Step 7: ëª¨ë¸ ì €ì¥ ë° í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œ\n",
    "\n",
    "# 1. í›ˆë ¨ëœ ëª¨ë¸ì„ ë¡œì»¬ì— ì €ì¥\n",
    "import os\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# ARTì—ì„œ í›ˆë ¨ëœ LoRA ì–´ëŒ‘í„° ì €ì¥\n",
    "print(\"Saving trained model...\")\n",
    "lora_model_path = (\n",
    "    f\".art/{model.project}/models/{model.name}/checkpoints/{await model.get_step():04d}\"\n",
    ")\n",
    "\n",
    "# ART ëª¨ë¸ì„ ì €ì¥ (LoRA ì–´ëŒ‘í„° í¬í•¨)\n",
    "peft_model, peft_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=lora_model_path,\n",
    "    max_seq_length=16384,\n",
    "    dtype=torch.bfloat16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# í—ˆê¹…í˜ì´ìŠ¤ í† í° í™•ì¸\n",
    "if not HF_TOKEN:\n",
    "    print(\"HUGGINGFACE_TOKENì´ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "if HF_TOKEN and HF_USERNAME:\n",
    "    try:\n",
    "        # HuggingFace API ì´ˆê¸°í™”\n",
    "        peft_model.push_to_hub_merged(\n",
    "            f\"{HF_USERNAME}/{model.name}\", peft_tokenizer, token=HF_TOKEN\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Model successfully uploaded to: https://huggingface.co/{repo_id}\")\n",
    "        \n",
    "        # W&Bì— í—ˆê¹…í˜ì´ìŠ¤ ë§í¬ ë¡œê¹…\n",
    "        wandb.log({\n",
    "            \"huggingface_model_url\": f\"https://huggingface.co/{repo_id}\",\n",
    "            \"final_model_saved\": True\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error uploading to Hugging Face: {str(e)}\")\n",
    "        print(\"Please check your token and internet connection.\")\n",
    "        \n",
    "else:\n",
    "    print(\"âš ï¸  Hugging Face í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"í—ˆê¹…í˜ì´ìŠ¤ì— ì—…ë¡œë“œí•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:\")\n",
    "    print(\"1. https://huggingface.co/settings/tokens ì—ì„œ í† í° ìƒì„±\")\n",
    "    print(\"2. HF_TOKEN ë³€ìˆ˜ì— ì‹¤ì œ í† í° ê°’ ì„¤ì •\")\n",
    "    print(\"3. HF_USERNAMEì„ ë³¸ì¸ì˜ í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ìš©ìëª…ìœ¼ë¡œ ë³€ê²½\")\n",
    "\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë¸ ì €ì¥ ë° ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"ğŸ“Š W&Bì—ì„œ í›ˆë ¨ ì§„í–‰ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”: https://wandb.ai\")\n",
    "\n",
    "# W&B ì‹¤í–‰ ì¢…ë£Œ\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f16551b",
   "metadata": {},
   "source": [
    "## Step 8: í—ˆê¹…í˜ì´ìŠ¤ì— ì—…ë¡œë“œí•œ ëª¨ë¸ ë¡œë“œí•˜ê³  í…ŒìŠ¤íŠ¸ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unslothë¡œ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì—ì„œ í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ìš©ìëª… ê°€ì ¸ì˜¤ê¸°\n",
    "HF_USERNAME = os.environ.get(\"HF_USERNAME\")  # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "model_repo = f\"{HF_USERNAME}/{model_name}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68bbde",
   "metadata": {},
   "source": [
    "# ê²°ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d3f3d",
   "metadata": {},
   "source": [
    "ì´ ê¸€ì—ì„œëŠ” OpenPipe ARTë¥¼ ê¸°ì´ˆì ì¸ ëª©ì ë¶€í„° ì‹¤ì œ êµ¬í˜„ê¹Œì§€ ê¹Šì´ ìˆê²Œ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. OpenPipe ARTëŠ” ì–¸ì–´ ëª¨ë¸ ì—ì´ì „íŠ¸ì— ê°•í™”í•™ìŠµì„ ì†ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ëŠ” ì „í†µì ì¸ ê°•í™”í•™ìŠµ í”„ë ˆì„ì›Œí¬ì˜ ì—¬ëŸ¬ í•œê³„ë¥¼ í•´ê²°í•˜ëŠ”ë°, ë‹¤ì¤‘ í„´ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ì§€ì›í•˜ê³ , í´ë¼ì´ì–¸íŠ¸-ì„œë²„ ì•„í‚¤í…ì²˜ë¥¼ í†µí•œ GPU í™œìš© ê·¹ëŒ€í™”, OpenAI ìŠ¤íƒ€ì¼ì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ê¸°ì¡´ ì½”ë“œë² ì´ìŠ¤ì™€ì˜ ì†ì‰¬ìš´ í†µí•©ì´ ê·¸ ì˜ˆì…ë‹ˆë‹¤. \n",
    "ì‹¤ë¬´ìì—ê²Œ ì´ëŠ” ê³§, ì„±ëŠ¥ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ì‹¤ìˆ˜ë¥¼ ë°˜ë³µí•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë‹¨ìˆœí•œ ì •ì  íŒŒì¸íŠœë‹ì´ ì•„ë‹ˆë¼ ê²½í—˜ì„ í†µí•´ ê°œì„ í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê·¸ ê²°ê³¼ë¡œ ì‹ ë¢°ì„± í–¥ìƒ(ê³¼ê±°ì˜ ì‹¤ìˆ˜ë¥¼ íšŒí”¼), ë” ë‚˜ì€ ê³¼ì œ ìˆ˜í–‰, ë°°í¬ëœ ì‹œìŠ¤í…œì—ì„œì˜ ì§€ì† í•™ìŠµ ê°€ëŠ¥ì„±ì´ë¼ëŠ” ì´ì ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "ìš°ë¦¬ëŠ” ART í•™ìŠµ ë£¨í”„ë¥¼ ì„¤ì •í•˜ëŠ” ë°©ë²•ì„ ì‹œì—°í•˜ê³ , Weights & Biases(W&B) í†µí•©ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. W&Bì˜ Weaveì™€ Modelsë¥¼ í™œìš©í•˜ë©´ í•™ìŠµ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  í•™ìŠµëœ ëª¨ë¸ì„ ê´€ë¦¬í•  ìˆ˜ ìˆì–´, ì‹¤í—˜ ê³¼ì •ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤. ë‹¨ìˆœí•œ ê³±ì…ˆ ë¬¸ì œ í•™ìŠµ ì˜ˆì‹œëŠ” ë³µì¡í•œ ì‘ì—…ì„ ë‹¤ë£° ë•Œì˜ ì ‘ê·¼ ë°©ì‹ì„ ë‹¨ìˆœí™”í•´ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ì—ˆìœ¼ë©°, ë™ì¼í•œ ì›ë¦¬ê°€ ë³µì¡í•œ ì˜ì‚¬ê²°ì •ì´ë‚˜ ë„êµ¬ ì‚¬ìš©ê³¼ ê°™ì€ ì‘ì—…ì„ í•™ìŠµí•˜ëŠ” ë°ì—ë„ ì ìš©ë©ë‹ˆë‹¤. ì¦‰, ì‘ì—…ì„ ì •ì˜í•˜ê³ , ë³´ìƒìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µí•˜ë©°, ë‚˜ë¨¸ì§€ëŠ” ARTì— ë§¡ê¸°ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì•ìœ¼ë¡œë¥¼ ë‚´ë‹¤ë³´ë©´, OpenPipe ARTëŠ” í™œë°œíˆ ì§„í™”í•˜ê³  ìˆëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. í–¥í›„ ë°œì „ ë°©í–¥ì€ ë‹¤ìŒê³¼ ê°™ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "ê°•í™”ëœ ë³´ìƒ ëª¨ë¸ë§: í˜„ì¬ëŠ” ë³´ìƒì„ ì§ì ‘ ì •ì˜í•˜ê±°ë‚˜ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ì„ ì‚¬ìš©í•˜ì§€ë§Œ, ì•ìœ¼ë¡œëŠ” í•™ìŠµëœ ë³´ìƒ ëª¨ë¸ì´ë‚˜ ì¸ê°„ í”¼ë“œë°±(RLHFì™€ ìœ ì‚¬)ì„ ì§ì ‘ í™œìš©í•˜ëŠ” ê³ ê¸‰ ê¸°ë²•ì´ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ARTëŠ” ì´ë¯¸ RULERë¼ëŠ” ê¸°ëŠ¥ì„ ë„ì…í•´ LLMì„ íŒì •ìë¡œ í™œìš©, ê²½ë¡œë¥¼ ì ìˆ˜í™”í•˜ê³  ìˆ˜ì‘ì—… ë³´ìƒ í•¨ìˆ˜ì˜ í•„ìš”ì„±ì„ í¬ê²Œ ì¤„ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì€ ì—ì´ì „íŠ¸ì˜ â€œì„±ê³µâ€ ê¸°ì¤€ ì •ì˜ë¥¼ ë” ì‰½ê²Œ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë” í­ë„“ì€ ëª¨ë¸ ì§€ì›ê³¼ í™•ì¥ì„±: ëŒ€ê·œëª¨ ë° íŠ¹ìˆ˜í™” ëª¨ë¸ì´ ë“±ì¥í•¨ì— ë”°ë¼ ARTëŠ” ì´ë¥¼ ì§€ì›í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í™•ì¥ë  ê²ƒì…ë‹ˆë‹¤. í”„ëŸ°íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œì˜ ë¶„ë¦¬ ë•ë¶„ì— ë¶„ì‚° í•™ìŠµì´ë‚˜ ëŒ€ê·œëª¨ ëª¨ë¸ì˜ í•˜ë“œì›¨ì–´ ìƒ¤ë”©ê¹Œì§€ ê°€ëŠ¥ì„±ì´ ì—´ë ¤ ìˆìœ¼ë©°, ìƒˆë¡œìš´ í•˜ë“œì›¨ì–´ ìµœì í™”ë‚˜ GRPO ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„± ê°œì„ ë„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í”„ë¡œë•ì…˜ í†µí•©: í˜„ì¬ ARTëŠ” ì—°êµ¬ ë° í”„ë¡œí† íƒ€ì´í•‘ì— ì í•©í•˜ì§€ë§Œ, ì¥ê¸°ì ìœ¼ë¡œëŠ” ì‹¤ì œ ì„œë¹„ìŠ¤ì— í†µí•©ë  ë„êµ¬ë“¤ì´ ë“±ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‹¤ì œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ í•™ìŠµí•˜ì—¬(ì ì ˆí•œ ì•ˆì „ì¥ì¹˜ì™€ í•¨ê»˜) ë°°í¬ëœ ì—ì´ì „íŠ¸ê°€ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ë¯¸ë˜ì—ëŠ” ì´ëŸ¬í•œ ì§€ì† í•™ìŠµì„ ì•ˆì „í•˜ê³  ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ ì¶”ê°€ë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬ì™€ ìƒíƒœê³„: ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì¸ ë§Œí¼, ARTì˜ ë°œì „ì€ ì‚¬ìš©ì ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ì—¬ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. LangChain ê°™ì€ ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ì˜ í†µí•©, ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ë¼ì´ë¸ŒëŸ¬ë¦¬, ë” ë§ì€ ì˜ˆì œë“¤ì´ ìƒê²¨ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ W&B ìƒíƒœê³„ì™€ì˜ ê²°í•©ì„ í†µí•´ ê³µê°œ ëŒ€ì‹œë³´ë“œ, ë¦¬í¬íŠ¸, ëª¨ë²” ì‚¬ë¡€ ê³µìœ  ë“±ì´ í™œë°œíˆ ì´ë£¨ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "OpenPipe ARTëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ AI ì—ì´ì „íŠ¸ì— ê°•í™”í•™ìŠµì„ ì‹¤ìš©ì ìœ¼ë¡œ ì ìš©í•˜ëŠ” ë° ìˆì–´ ì¤‘ìš”í•œ ì§„ì „ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê°œë°œìë“¤ì€ ì •ì ì¸ ëª¨ë¸ ì„±ëŠ¥ì„ ë„˜ì–´, ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•œ ì§€ì†ì ì¸ í–‰ë™ ê°œì„ ì„ ê°€ëŠ¥í•˜ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ììœ¨ ì—ì´ì „íŠ¸ë‚˜ ë³µì¡í•œ ì±—ë´‡ì„ ë§Œë“¤ê³  ìˆëŠ”ë° ê¸°ëŒ€ë§Œí¼ ê°•ê±´í•˜ê±°ë‚˜ ì •í™•í•˜ì§€ ì•Šë‹¤ë©´, ARTë¥¼ ê³ ë ¤í•´ë³´ì‹­ì‹œì˜¤. ìµœì†Œí•œì˜ ìˆ˜ì •ë§Œìœ¼ë¡œ ì—ì´ì „íŠ¸ì— í•™ìŠµ ë£¨í”„ë¥¼ ë‚´ì¥í•  ìˆ˜ ìˆê³ , ì ì°¨ ê°œì„ ë˜ëŠ” ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ W&B ê°™ì€ ë„êµ¬ë¡œ í•™ìŠµ ê³¼ì •ì„ ì¶”ì í•˜ë©´, í•™ìŠµ ê³¼ì •ì„ ì™„ì „íˆ íˆ¬ëª…í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "OpenPipe ARTì˜ ë¯¸ë˜ëŠ” ë§¤ìš° ë°ìŠµë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ ê°œë°œ, ì„±ì¥í•˜ëŠ” ì‚¬ìš©ì ì»¤ë®¤ë‹ˆí‹°, MLOps ë„êµ¬ì™€ì˜ í†µí•©ì´ ë§ë¬¼ë ¤, ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì•ìœ¼ë¡œ í‘œì¤€ì ì¸ ì—ì´ì „íŠ¸ í•™ìŠµ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ìë¦¬ ì¡ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ììœ¨ì ì¸ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ê°€ í•  ìˆ˜ ìˆëŠ” ì¼ì˜ ë²”ìœ„ë¥¼ ê³„ì†í•´ì„œ í™•ì¥ì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì¦ê±°ìš´ í•™ìŠµ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤! ë” ê¹Šì´ íƒêµ¬í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´, ê´€ë ¨ ì˜ˆì œë¥¼ í™•ì¸í•˜ê³  OpenPipe ì»¤ë®¤ë‹ˆí‹°ì— ì°¸ì—¬í•´ ë³´ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤. ê²Œì„ í”Œë ˆì´ ì—ì´ì „íŠ¸ë“ , ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ í†µí•´ í•™ìŠµí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë“ , OpenPipe ARTì™€ W&BëŠ” ë” ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ë° í•„ìš”í•œ í”¼ë“œë°± ë£¨í”„ë¥¼ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc2e2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
