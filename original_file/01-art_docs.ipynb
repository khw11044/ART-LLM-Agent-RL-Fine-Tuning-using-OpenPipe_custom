{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6157b9c7",
   "metadata": {},
   "source": [
    "# ART Docs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03293cea",
   "metadata": {},
   "source": [
    "ART (Agent Reinforcement Trainer) : An open-source framework for LLM reinforcement learning using GRPO\n",
    "\n",
    "\n",
    "GRPOë¥¼ ì‚¬ìš©í•˜ëŠ” LLM ê°•í™”í•™ìŠµì„ ìœ„í•œ open-source í”„ë ˆì„ì›Œí¬ì¸ ARTë¥¼ ì´ìš©í•˜ì—¬ \n",
    "\n",
    "ìì‹ ë§Œì˜ multi-turn agentsë¥¼ í›ˆë ¨ì‹œì¼œë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6c575",
   "metadata": {},
   "source": [
    "ART (Agent Reinforcement Trainer)ëŠ” Agentic LLMsì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ open-source training frameworkë¡œ\n",
    "\n",
    "**ê²½í—˜** ì„ í†µí•´ **ì„±ëŠ¥ê³¼ ì‹ ë¢°ì„±**ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ARTëŠ” GRPO (Group Relative Policy Optimization)ê³¼ ê°™ì€ ê°•í™”í•™ìŠµ ê¸°ìˆ ë“¤ì„ í¸ë¦¬í•˜ê²Œ wrapperë¡œ ì œê³µí•˜ì—¬ ìµœì†Œí•œì˜ í›ˆë ¨ ë¹„ìš©ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ì˜ ê·¹ì ì¸ í–¥ìƒì„ ì´ë£° ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb96b5ab",
   "metadata": {},
   "source": [
    "# Why ART? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885c8e3",
   "metadata": {},
   "source": [
    "- ARTëŠ” ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— RL trainingì„ ë„ì…í•˜ê¸° ìœ„í•œ í¸ë¦¬í•œ wrappersë“¤ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ê°œë°œìì˜ ì½”ë“œì™€ ìƒí˜¸ ì‘ìš©í•  í•„ìš”ê°€ ì—†ëŠ” ëª¨ë“ˆì‹ ì„œë¹„ìŠ¤ë¡œ í›ˆë ¨ ì„œë²„ë¥¼ ì¶”ìƒí™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **Train from anywhere.** ë…¸íŠ¸ë¶ì—ì„œ ART í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ART ì„œë²„ê°€ ì„ì‹œ GPU ì§€ì› í™˜ê²½ì„ ì‹œì‘í•˜ë„ë¡ í•˜ê±°ë‚˜ ë¡œì»¬ GPUì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "- W&B, Langfuse, OpenPipeì™€ ê°™ì€ í˜¸ìŠ¤íŒ… í”Œë«í¼ê³¼ì˜ í†µí•©ì€ ìœ ì—°í•œ ê´€ì°°ì„±ì„ ì œê³µí•˜ê³  ë””ë²„ê¹…ì„ ê°„ì†Œí™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ARTëŠ” ì§€ëŠ¥í˜• ê¸°ë³¸ê°’ì„ í†µí•´ ì‚¬ìš©ì ì •ì˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. íŠ¹ì • ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ í•™ìŠµ ë§¤ê°œë³€ìˆ˜ì™€ ì¶”ë¡  ì—”ì§„ êµ¬ì„±ì„ êµ¬ì„±í•˜ê±°ë‚˜, í•™ìŠµ íš¨ìœ¨ì„±ê³¼ ì•ˆì •ì„±ì„ ìœ„í•´ ìµœì í™”ëœ ê¸°ë³¸ê°’ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c57a4",
   "metadata": {},
   "source": [
    "# What is RL and when should I use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba4b62",
   "metadata": {},
   "source": [
    "RL (reinforcement learning)ì€ AI model ìì‹ ì˜ ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµí•  ìˆ˜ ìˆê²Œí•˜ëŠ” training ê¸°ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "RLì„ ê¸°ì¡´ LLMì— ì ìš©í•˜ëŠ” ê²ƒì€ ë‹¤ìŒê³¼ ê°™ì€ ê²ƒë“¤ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: \n",
    "- ì „ë°˜ì ì¸ agent ì‹ ë¢°ì„± í–¥ìƒ \n",
    "- QA ë˜ëŠ” ìƒì‚° ê³¼ì •ì—ì„œ ë°œê²¬ëœ íŠ¹ì • ì‹¤ìˆ˜ë¥¼ ìˆ˜ì •\n",
    "- ì‚¬ìš©ìì—ê²Œ ë°°í¬í•˜ê¸° ì „ì— agent ì„±ëŠ¥ì˜ ì‹ ë¢°ì„± êµ¬ì¶• \n",
    "\n",
    "Examples:\n",
    "- knowledge storeë¡œë¶€í„° searchí•˜ê³  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ deep research agent í›ˆë ¨ \n",
    "- ìƒˆë¡œìš´ training examplesë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ëª¨ë¸ behaviorì— ë°œìƒí•˜ëŠ” ì§œì¦ë‚˜ëŠ” ë²„ê·¸ í•´ê²°\n",
    "- ë§¤ë²ˆ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë”°ë¥´ëŠ” ì´ˆê³ ì† ìŒì„± ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f83ea",
   "metadata": {},
   "source": [
    "# What do I need in order to use RL?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059d735",
   "metadata": {},
   "source": [
    "\n",
    "### í•„ìš”í•œê²ƒ \n",
    "- âœ… í•˜ë‚˜ ë˜ëŠ” ê·¸ ì´ìƒì˜ LLMì„ ì‚¬ìš©í•  í”„ë¡œì íŠ¸\n",
    "- âœ… LLMì´ ì²˜ë¦¬í•´ì•¼ í•  ì‹œë‚˜ë¦¬ì˜¤ ì¢…ë¥˜ì— ëŒ€í•œ ì§€ì‹\n",
    "\n",
    "### í•„ìš”í•˜ì§€ ì•ŠëŠ” ê²ƒ \n",
    "- âŒ training dataset \n",
    "- âŒ ì™„ì„±ëœ reward (ë³´ìƒ) í•¨ìˆ˜ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f174d",
   "metadata": {},
   "source": [
    "# Tutorial: Implementing OpenPipe ART with Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0274f1c",
   "metadata": {},
   "source": [
    "í•´ë‹¹ íŠœí† ë¦¬ì–¼ì—ì„œ ìš°ë¦¬ëŠ” ARTë¥¼ simple agent taskì— ì ìš©í•˜ê³  Weights & Biases (W&B)ë¥¼ ì‚¬ìš©í•˜ì—¬ training progressë¥¼ ì¶”ì í•  ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "ìš°ë¦¬ agentì˜ taskëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§ê´€ì ì…ë‹ˆë‹¤: ê°„ë‹¨í•œ ê³±ì…ˆ ë¬¸ì œë¥¼ í‘¸ëŠ”ê²ƒ\n",
    "\n",
    "ì²˜ìŒì—ëŠ”, ìš°ë¦¬ì˜ language modelì€ ê³±ì…ˆì„ í•˜ëŠ”ë° ì‹¤ìˆ˜ë¥¼ í• ê²ƒì…ë‹ˆë‹¤, ê·¸ëŸ¬ë‚˜ ARTë¥¼ ì´ìš©í•˜ë©´, ì´ê²ƒì„ í›ˆë ¨ì‹œí‚¤ë©° ê°œì„ ì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” W&B Weaveì™€ W&B Modelsë“¤ë¡œ ì–´ë–»ê²Œ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•˜ëŠ”ì§€ ì•Œë ¤ì¤„ ê²ƒì´ë©°, trained modelì„ ë‹¤ë£¨ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤„ ê²ƒì…ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba62c9e",
   "metadata": {},
   "source": [
    "í•„ìˆ˜ì¡°ê±´: W&B ê³„ì •ì´ ìˆì–´ì•¼í•˜ê³  Pythonì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¹ì‹ ì€ ë‹¹ì‹ ì˜ local machoneì—ì„œ ê°•ë ¥í•œ GPUë¥¼ ì¤€ë¹„í•  í•„ìš” ì—†ìŠµë‹ˆë‹¤ - ìš°ë¦¬ëŠ” ë¡œì»¬ ì„¤ì •ì„ ì‚¬ìš©í•˜ì—¬ ì‹œì—°í•´ ë³´ê² ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ GPUê°€ ì—†ë‹¤ë©´ SkyPilot ë°±ì—”ë“œë¥¼ í†µí•´ ì›ê²© GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ ARTë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a66d9",
   "metadata": {},
   "source": [
    "## Step 1 : Install OpenPipe ART and set up W&B\n",
    "\n",
    "ë¨¼ì €, OpenPipe ART íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš” ê·¸ë¦¬ê³  ì‹¤í—˜ ì¶”ì ìœ¼ë¡œ ìœ„í•´ weights & Biasesì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤. \n",
    "ë‹¹ì‹ ì€ pipë¥¼ í†µí•´ openpipe-artë¥¼ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, W&B SDK (wandb)ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2cefafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openpipe-art wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9018329",
   "metadata": {},
   "source": [
    "Python script ë˜ëŠ” notebookì—ì„œ, W&Bë¥¼ ë¡œê·¸ì¸ í•˜ê³  ì´ˆê¸°í™” ì‹¤í–‰ì„ í•˜ì„¸ìš”: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede788d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyunew\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/khw/Workspace/llm/openpipe/01.Tutorial/wandb/run-20250919_162325-mifxs6ij</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hyunew/my-agentic-task/runs/mifxs6ij' target=\"_blank\">openpipe-art-demo</a></strong> to <a href='https://wandb.ai/hyunew/my-agentic-task' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hyunew/my-agentic-task' target=\"_blank\">https://wandb.ai/hyunew/my-agentic-task</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hyunew/my-agentic-task/runs/mifxs6ij' target=\"_blank\">https://wandb.ai/hyunew/my-agentic-task/runs/mifxs6ij</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hyunew/my-agentic-task/runs/mifxs6ij?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x76b998f6add0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "wandb.login()  # you'll be prompted to enter your W&B API key (from your W&B account page)\n",
    "wandb.init(project=\"my-agentic-task\", name=\"openpipe-art-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf479c3",
   "metadata": {},
   "source": [
    "`wandb.init` í˜¸ì¶œì€ í”„ë¡œì íŠ¸(ì´ ê²½ìš° \"my-agentic-task\")ì™€ ì¶”ì ì„ ìœ„í•œ ì‹¤í–‰ ì´ë¦„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ë¡œê¹…í•˜ëŠ” ëª¨ë“  ì§€í‘œê°€ W&B ëŒ€ì‹œë³´ë“œì— ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡ë©ë‹ˆë‹¤. (W&Bë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë ¤ë©´ ë¡œê·¸ì¸/ì´ˆê¸°í™” ë‹¨ê³„ë¥¼ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ARTëŠ” ì´ ë‹¨ê³„ ì—†ì´ë„ ì‘ë™í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ êµìœ¡ ê³¼ì •ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì–»ìœ¼ë ¤ë©´ ì´ ë‹¨ê³„ë¥¼ ì ê·¹ ê¶Œì¥í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa7ef7c",
   "metadata": {},
   "source": [
    "## Step 2 : Initialize the ART model and backendNext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c5d11",
   "metadata": {},
   "source": [
    "ìš°ë¦¬ëŠ” trainable modelê³¼ training backendë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. \n",
    "\n",
    "íŒŒì¸íŠœë‹ í•˜ê¸°ìœ„í•´ base modelì„ ì§€ì •í•´ì£¼ì„¸ìš”. OpenPipe ARTëŠ” ë§ì€ Hugging Face-compatible LLMsë“¤ì„ ì§€ì›í•©ë‹ˆë‹¤; ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ë°ëª¨ë¥¼ ìœ„í•´, (ìƒëŒ€ì ìœ¼ë¡œ lightweight modelì¸) Qwen 3B instruct modelê³¼ ê°™ì€ smaller modelì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ model ì´ë¦„ì„ ì§€ì–´ì£¼ê³  ë¡œê·¸ì¸ì„ ìœ„í•´ W&B projectë¥¼ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ë°±ì—”ë“œì˜ ê²½ìš°, ë¡œì»¬ ë°±ì—”ë“œ(ì‚¬ìš© ê°€ëŠ¥í•œ GPUê°€ ìˆë‹¤ëŠ” ê°€ì • í•˜ì—)ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ë¡œì»¬ì— GPUê°€ ì—†ë‹¤ë©´ SkyPilotBackendë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ê²© ë°±ì—”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b41c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khw/miniconda3/envs/openpipe/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-19 16:23:34 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khw/miniconda3/envs/openpipe/lib/python3.11/site-packages/art/__init__.py:10: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  import unsloth  # type: ignore # noqa: F401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 09-19 16:23:41 [__init__.py:235] Automatically detected platform cuda.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: Patching vLLM v1 graph capture\n",
      "Unsloth: Patching vLLM v0 graph capture\n",
      "==((====))==  Unsloth 2025.8.6: Fast Qwen2 patching. Transformers: 4.53.2. vLLM: 0.10.0.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 2. Max memory: 39.394 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/qwen2.5-3b-unsloth-bnb-4bit with actual GPU utilization = 78.07%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.39 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 32768. Num Sequences = 320.\n",
      "Unsloth: vLLM's KV Cache can use up to 28.53 GB. Also swap space = 6 GB.\n",
      "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
      "INFO 09-19 16:24:03 [config.py:1604] Using max model len 32768\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.1.mlp', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.28.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
      "INFO 09-19 16:24:04 [llm_engine.py:228] Initializing a V0 LLM engine (v0.10.0) with config: model='unsloth/qwen2.5-3b-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/qwen2.5-3b-unsloth-bnb-4bit, num_scheduler_steps=16, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":true,\"trace.graph_diagram\":false,\"compile_threads\":32,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":320,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 09-19 16:24:06 [cuda.py:398] Using Flash Attention backend.\n",
      "INFO 09-19 16:24:06 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 09-19 16:24:06 [model_runner.py:1083] Starting to load model unsloth/qwen2.5-3b-unsloth-bnb-4bit...\n",
      "INFO 09-19 16:24:07 [bitsandbytes_loader.py:733] Loading weights with BitsAndBytes quantization. May take a while ...\n",
      "INFO 09-19 16:24:08 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "INFO 09-19 16:24:09 [weight_utils.py:349] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 16.75it/s]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.01s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.01s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-19 16:24:10 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "INFO 09-19 16:24:11 [model_runner.py:1115] Model loading took 2.4441 GiB and 3.511720 seconds\n",
      "INFO 09-19 16:24:15 [worker.py:295] Memory profiling takes 3.90 seconds\n",
      "INFO 09-19 16:24:15 [worker.py:295] the current vLLM instance can use total_gpu_memory (39.39GiB) x gpu_memory_utilization (0.78) = 30.75GiB\n",
      "INFO 09-19 16:24:15 [worker.py:295] model weights take 2.44GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 2.69GiB; the rest of the memory reserved for KV Cache is 25.53GiB.\n",
      "INFO 09-19 16:24:16 [executor_base.py:113] # cuda blocks: 46468, # CPU blocks: 10922\n",
      "INFO 09-19 16:24:16 [executor_base.py:118] Maximum concurrency for 32768 tokens per request: 22.69x\n",
      "INFO 09-19 16:24:21 [vllm_utils.py:671] Unsloth: Running patched vLLM v0 `capture_model`.\n",
      "INFO 09-19 16:24:21 [model_runner.py:1385] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:16<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-19 16:24:37 [model_runner.py:1537] Graph capturing finished in 17 secs, took 5.68 GiB\n",
      "INFO 09-19 16:24:37 [vllm_utils.py:678] Unsloth: Patched vLLM v0 graph capture finished in 17 secs.\n",
      "INFO 09-19 16:24:38 [llm_engine.py:424] init engine (profile, create kv cache, warmup model) took 27.09 seconds\n",
      "Unsloth: Just some info: will skip parsing ['q_norm', 'post_feedforward_layernorm', 'pre_feedforward_layernorm', 'k_norm']\n",
      "Unsloth: Just some info: will skip parsing ['q_norm', 'post_feedforward_layernorm', 'pre_feedforward_layernorm', 'k_norm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.6 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "import art  # import the OpenPipe ART library\n",
    "from art.local import LocalBackend\n",
    "\n",
    "# Create a trainable model instance\n",
    "model = art.TrainableModel(\n",
    "    name=\"agent-001\",                # an arbitrary name for your model (used for logging)\n",
    "    project=\"my-agentic-task\",       # W&B project name for grouping runs\n",
    "    base_model=\"Qwen/Qwen2.5-3B\",    # base model to fine-tune (needs to be a model identifier or path)\n",
    ")\n",
    "\n",
    "\n",
    "# Set up the training backend\n",
    "backend = LocalBackend()  # use local GPU; ensure your machine has a GPU and drivers if using this\n",
    "\n",
    "\n",
    "# If no local GPU, you can use SkyPilotBackend as follows:\n",
    "# from art.skypilot import SkyPilotBackend\n",
    "# backend = await SkyPilotBackend.initialize_cluster(cluster_name=\"art-demo\", gpu=\"A10\")  \n",
    "# (The above would asynchronously provision a remote GPU machine, e.g., with an Nvidia A10 card.)\n",
    "\n",
    "\n",
    "# Register the model with the backend (prepare the backend server)\n",
    "await model.register(backend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e142a3d",
   "metadata": {},
   "source": [
    "- `TrainableModel` ëŠ” modelì„ ì…‹ì—…í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” `base_model=\"Qwen/Qwen2.5-3B` ë¥¼ ì˜ˆì œë¡œ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ART ì‹œìŠ¤í…œì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤ (Hugging Face Hubì˜ ê³µê°œ ëª¨ë¸ì¸ ê²½ìš° ARTì—ì„œ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤). ë˜í•œ ë‹¹ì‹ ì´ fine-tuningí•˜ê¸° ì›í•˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ë¡œ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "- trainingì„ ìœ„í•´ local server processë¥¼ ëŸ°ì¹­í•  `LocalBackend` ë¥¼ ë§Œë“­ë‹ˆë‹¤. ` await model.register(backend)` ë¥¼ í˜¸ì¶œí•˜ë©´, ARTëŠ” ë°±ì•¤ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ë°±ì•¤ë“œì˜ vLLM ì„œë²„ì—ì„œ ëª¨ë¸ì„ ë¡œë”©í•˜ê³  í›ˆë ¨í•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤). ì´ stepì€ model weightsë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ê¸° ë•Œë¬¸ì—, ì´ˆê¸°ì— ì‹œê°„ì„ ì¡°ê¸ˆ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "\n",
    "- Note: `await` ëŠ” `register`ê°€ asynchronous operation ì„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  top-level `await`ë¥¼ ì§€ì›í•˜ëŠ” ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œëŠ” ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ Python scriptì—ì„œëŠ” `asyncio` event loop ë‚´ì—ì„œ ì´ë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ê°„ë‹¨í•˜ê²Œ, ì´ ì½”ë“œëŠ” notebook ì•ˆì— ë˜ëŠ” async context ì•ˆì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. (ë§Œì•½, scriptë¥¼ ì‚¬ìš©í•˜ë©´, ì´ëŸ¬í•œ í˜¸ì¶œì„ `async def main()`ìœ¼ë¡œ wrappingí•˜ê³  `asyncio.run(main())`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048c580",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì€ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ë¡ ê³¼ í•™ìŠµì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°±ì—”ë“œì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ê°•í™” í•™ìŠµ ë£¨í”„ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec909a2",
   "metadata": {},
   "source": [
    "## Step 3: Define the task and the reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305a5fe",
   "metadata": {},
   "source": [
    "í•´ë‹¹ íŠœí† ë¦¬ì–¼ì—ì„œ ìš°ë¦¬ì˜ taskëŠ” ê°„ë‹¨í•©ë‹ˆë‹¤: 2ê°œì˜ ìˆ˜ê°€ ì£¼ì–´ì§€ë©´, agent (model)ì€ ì´ ë‘ ìˆ˜ì˜ ê³±ì…ˆì„ ì¶œë ¥í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í•´ë‹¹ ëª¨ë¸ì— ëŒ€í•´ question-answer interactionìœ¼ë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ë“¤ì–´, ìš°ë¦¬ëŠ” \"What is 12*13?\" ì„ ì œì‹œí•˜ë©´, ëŒ€ë‹µìœ¼ë¡œ \"156\" ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ë§Œì•½ ëª¨ë¸ì˜ ëŒ€ë‹µì´ ì˜³ë‹¤ë©´, ìš°ë¦¬ëŠ” positive rewardë¥¼ ì£¼ê³ , ë§Œì¼ í‹€ë ¸ë‹¤ë©´, ìš°ë¦¬ëŠ” negative rewardë¥¼ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼, ëª¨ë¸ì€ ë” ë§ì€ ë³´ìƒì„ ë°›ê¸° ìœ„í•´ ì¶œë ¥ì„ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤(ì¦‰, ë³´ì´ëŠ” ìˆ«ì ë²”ìœ„ì— ë§ê²Œ ì˜¬ë°”ë¥´ê²Œ ê³±í•˜ëŠ” ë²•ì„ ë°°ì›Œì•¼ í•©ë‹ˆë‹¤).\n",
    "\n",
    "ìš°ë¦¬ëŠ” rollout functionì„ ì •ì˜í•´ì•¼í•©ë‹ˆë‹¤: ì´ functionì€ agentì˜ í•œ episode/interactionì„ ì‹¤í–‰í•˜ê³  `Trajectory` (ë©”ì‹œì§€ ì‹œí€€ìŠ¤ ê·¸ë¦¬ê³  final reward) ë¥¼ return í•©ë‹ˆë‹¤. \n",
    "ARTì—ì„œ, ì¼ë°˜ì ìœ¼ë¡œ `model.openai_clinet()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ê³¼ interactí•  ìˆ˜ ìˆëŠ” **rollout function**ì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” ê³±ì…ˆ ì‘ì—…ì— ëŒ€í•œ ë‹¨ìˆœí™”ëœ rollout functionì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16372cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "# Define one scenario rollout for the multiplication task\n",
    "async def rollout(model: art.TrainableModel) -> art.Trajectory:\n",
    "    # Step 1: Prepare a random multiplication problem\n",
    "    a = random.randint(1, 20)\n",
    "    b = random.randint(1, 20)\n",
    "    question = f\"What is {a} * {b}?\"\n",
    "    # We use the model's OpenAI-compatible client for inference\n",
    "    openai_client = model.openai_client()\n",
    "    # Create the conversation message (system prompt can be empty or an instruction)\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    # Step 2: Get the model's answer\n",
    "    completion = await openai_client.chat.completions.create(\n",
    "        model=model.name,\n",
    "        messages=messages,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    answer = completion.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "    # Step 3: Calculate reward based on correctness\n",
    "    correct_answer = str(a * b)\n",
    "    if answer == correct_answer:\n",
    "        reward_value = 1.0   # correct answer, positive reward\n",
    "    else:\n",
    "        reward_value = -1.0  # incorrect answer, negative reward\n",
    "\n",
    "\n",
    "    # Step 4: Package into a Trajectory and assign reward\n",
    "    trajectory = art.Trajectory(messages=messages + [{\"role\": \"assistant\", \"content\": answer}])\n",
    "    trajectory.reward = reward_value\n",
    "    return trajectory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50057f16",
   "metadata": {},
   "source": [
    "ìœ„ rollout ì½”ë“œë¥¼ íŒŒí•´ì³ë´…ì‹œë‹¤.\n",
    "\n",
    "- ê³±ì…ˆ ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•´ `a`ì™€ `b` 2ê°œì˜ ìˆ«ìë¥¼ ëœë¤ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- ì´ ìˆ«ìë“¤ì˜ ê³±ì„ ë¬»ëŠ” user messageë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. (ë” ë³µì¡í•œ agentì—ì„œëŠ” instructionì„ í¬í•¨í•œ system messageë„ ì¶”ê°€í•  ìˆ˜ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ êµ¬ì„±í•©ë‹ˆë‹¤)\n",
    "- ìš°ë¦¬ì˜ ëª¨ë¸ì—ì„œ `openai_client`ë¥¼ ê°€ì ¸ì˜¤ê³ , `chat.completions.create` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì‘ë‹µì„ ê°€ì ¸ì˜µë‹ˆë‹¤. `model=model.name`ì„ ì§€ì •í•˜ì—¬ ìš”ì²­ì´ ë°±ì—”ë“œì— ë“±ë¡í•œ fine-tuning ì¸ìŠ¤í„´ìŠ¤ë¡œ ì „ë‹¬ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "- ëª¨ë¸ì˜ ëŒ€ë‹µì´ ìº¡ì³ë©ë‹ˆë‹¤. formatting ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ í•´ë‹¹ ë‹µë³€ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "- ê·¸ëŸ°ë‹¤ìŒ rewardë¥¼ ê²°ì •í•©ë‹ˆë‹¤: ë§Œì¼ ëŒ€ë‹µì´ ì •ë‹µì´ë©´, reward = +1, ì•„ë‹ˆë©´, -1ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤. (ìš°ë¦¬ëŠ” ê°„ë‹¨í•œ reward ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤; ë” ë³µì¡í•œ taskëŠ” ë” ë³µì¡í•œ scoringì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
    "- ìš°ë¦¬ëŠ” `art.Trajectory` objectë¥¼ ìƒì„±í•˜ì—¬ interactionì„ ê¸°ë¡í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” user questionê³¼ assistant's answerë¥¼ ëª¨ë‘ messagesì— í¬í•¨í•©ë‹ˆë‹¤. ê·¸ëŸ°ë‹¤ìŒ, ìš°ë¦¬ëŠ” trajectoryì— rewardë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "- trajectoryê°€ returnë˜ì–´, í•´ë‹¹ í™˜ê²½ì—ì„œ agentì˜ í•œ rolloutì´ ìº¡ìŠí™”ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a009031",
   "metadata": {},
   "source": [
    "## Step 4: Run training iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe41b7b",
   "metadata": {},
   "source": [
    "ì •ì˜ëœ rollout functionê³¼ í•¨ê¼, ì—¬ëŸ¬ iterationsë¥¼ í†µí•´ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ê°•í™” í•™ìŠµì˜ ê´€ì ì—ì„œ ë³´ë©´, ìš°ë¦¬ëŠ” ì¼ë ¨ì˜ ì—í”¼ì†Œë“œë¥¼ ì§„í–‰í•˜ê³ , ê° ì—í”¼ì†Œë“œ ë°°ì¹˜ê°€ ëë‚  ë•Œë§ˆë‹¤ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë°ëª¨ë¥¼ ìœ„í•´, ìš°ë¦¬ëŠ” 50ë²ˆì˜ training setipì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ê° ìŠ¤í…ì—ì„œ, ìš°ë¦¬ëŠ” ì—¬ëŸ¬ ê³±ì…ˆ ë¬¸ì œë“¤ì„ agentì—ê²Œ ì œê³µí•©ë‹ˆë‹¤ (update ì „ì— ì¶©ë¶„í•œ ê²½í—˜ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´)\n",
    "\n",
    "\n",
    "OpenPipe ARTë¥¼ ì‚¬ìš©í•˜ì—¬, modelì„ training í•˜ëŠ” ê²ƒì€ \n",
    "\n",
    "\n",
    "OpenPipe ARTë¥¼ ì‚¬ìš©í•˜ë©´ ë¡¤ì•„ì›ƒì—ì„œ train methodë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒë§Œí¼ ì‰½ê²Œ ëª¨ë¸ì„ training í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì˜ˆë¥¼ ë“¤ì–´, ARTë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ ë¡¤ì•„ì›ƒì„ ê·¸ë£¹í™”í•˜ê³  ë‚´ë¶€ì ìœ¼ë¡œ trainingì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” trainingì— ëŒ€í•œ pseudo code ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92eb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a76d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_443543/371425098.py:8: RuntimeWarning: coroutine 'rollout' was never awaited\n",
      "  trajectories = [rollout(model) for _ in range(rollouts_per_step)]\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/khw/miniconda3/envs/openpipe/lib/python3.11/site-packages/vllm/entrypoints/openai/serving_chat.py:204: RuntimeWarning: coroutine 'AsyncMultiModalItemTracker.all_mm_data' was never awaited\n",
      "  return self.create_error_response(f\"{e} {e.__cause__}\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'object': 'error', 'message': 'As of transformers v4.44, default chat template is no longer allowed, so you must provide a chat template if the tokenizer does not define one. None', 'type': 'BadRequestError', 'param': None, 'code': 400}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m trajectories = [rollout(model) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rollouts_per_step)]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Wait for all the asynchronous rollouts to finish\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m trajectories = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*trajectories)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# (ART will automatically use these trajectories to train the model via GRPO)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# After this point, the model's parameters (LoRA weights) are updated on the backend.\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Log the mean reward of this batch for monitoring\u001b[39;00m\n\u001b[32m     17\u001b[39m avg_reward = \u001b[38;5;28msum\u001b[39m(t.reward \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trajectories) / \u001b[38;5;28mlen\u001b[39m(trajectories)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/openpipe/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/openpipe/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mrollout\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m     14\u001b[39m messages = [\n\u001b[32m     15\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: question}\n\u001b[32m     16\u001b[39m ]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Step 2: Get the model's answer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m completion = \u001b[38;5;28;01mawait\u001b[39;00m openai_client.chat.completions.create(\n\u001b[32m     19\u001b[39m     model=model.name,\n\u001b[32m     20\u001b[39m     messages=messages,\n\u001b[32m     21\u001b[39m     max_tokens=\u001b[32m10\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     23\u001b[39m answer = completion.choices[\u001b[32m0\u001b[39m].message.content.strip()\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Step 3: Calculate reward based on correctness\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/openpipe/lib/python3.11/site-packages/art/openai.py:34\u001b[39m, in \u001b[36mpatch_openai.<locals>.create_patched\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     32\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     33\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33minclude_usage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m return_value = \u001b[38;5;28;01mawait\u001b[39;00m create(*args, **kwargs)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_value, AsyncIterator):\n\u001b[32m     36\u001b[39m     report_usage(return_value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/openpipe/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:2028\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1985\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1986\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1987\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2025\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   2026\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   2027\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2028\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2029\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2030\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2031\u001b[39m             {\n\u001b[32m   2032\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2033\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2034\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2035\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2036\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2037\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2038\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2039\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2040\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2041\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2042\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2043\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2044\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2045\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2046\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2047\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2048\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2049\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2050\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2051\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2052\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2053\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2054\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2055\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2056\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2057\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2058\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2059\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2060\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2061\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2062\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2063\u001b[39m             },\n\u001b[32m   2064\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2065\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2066\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2067\u001b[39m         ),\n\u001b[32m   2068\u001b[39m         options=make_request_options(\n\u001b[32m   2069\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2070\u001b[39m         ),\n\u001b[32m   2071\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2072\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2073\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2074\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/openpipe/lib/python3.11/site-packages/openai/_base_client.py:1784\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1770\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1772\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1779\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1780\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1781\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1782\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1783\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/openpipe/lib/python3.11/site-packages/openai/_base_client.py:1584\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1581\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1583\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1584\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1586\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1588\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'object': 'error', 'message': 'As of transformers v4.44, default chat template is no longer allowed, so you must provide a chat template if the tokenizer does not define one. None', 'type': 'BadRequestError', 'param': None, 'code': 400}"
     ]
    }
   ],
   "source": [
    "# Train the model for a certain number of steps\n",
    "training_steps = 50\n",
    "rollouts_per_step = 8  # how many problems to attempt per step (parallel rollouts)\n",
    "\n",
    "\n",
    "for step in range(training_steps):\n",
    "    # Collect trajectories from multiple parallel rollouts\n",
    "    trajectories = [rollout(model) for _ in range(rollouts_per_step)]\n",
    "    # Wait for all the asynchronous rollouts to finish\n",
    "    trajectories = await asyncio.gather(*trajectories)\n",
    "\n",
    "\n",
    "    # (ART will automatically use these trajectories to train the model via GRPO)\n",
    "    # After this point, the model's parameters (LoRA weights) are updated on the backend.\n",
    "    \n",
    "    # Log the mean reward of this batch for monitoring\n",
    "    avg_reward = sum(t.reward for t in trajectories) / len(trajectories)\n",
    "    wandb.log({\"step\": step, \"average_reward\": avg_reward})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2decfb",
   "metadata": {},
   "source": [
    "ìœ„ ì½”ë“œì—ì„œ, ìš°ë¦°ëŠ” `rollout(model)` ì„ ë™ì‹œì— 8ë²ˆ ì‹¤í–‰ì‹œì¼œ ê²½í—˜ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ (async contextì¸ ê²½ìš° `asyncio.gather`ë¥¼ ì‚¬ìš©í•˜ì—¬) ëª¨ë“  í•­ëª©ì„ await í•˜ì—¬ trajectories resultsì˜ listë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ì´ëŸ° trajectoriesëŠ” agentì˜ interactonsê³¼ rewardë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì´ê²ƒë“¤ì´ ìˆ˜ì§‘ë˜ë©´, ARTì˜ backendëŠ” ë‚´ë¶€ì ìœ¼ë¡œ trainingì´ ì—…ë°ì´íŠ¸ ë ê²ƒì…ë‹ˆë‹¤. (ARTëŠ” ë‚´ë¶€ì ìœ¼ë¡œ trajectoriesë¥¼ ê·¸ë£¹í™”í•˜ê³  GRPO ìµœì í™” ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì˜ policyë¥¼ ê°œì„ í•©ë‹ˆë‹¤.)\n",
    "\n",
    "ìš°ë¦¬ëŠ” ë˜í•œ rolloutsì˜ batchì— ëŒ€í•´ reward í‰ê· ì„ W&Bì— ë¡œê¹…í•©ë‹ˆë‹¤. ì´ê²ƒì€ training progressì™€ ê°™ì€ ê²ƒì„ ë³´ê¸°ì— ìœ ìš©í•œ ì§€í‘œì…ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ë˜í•œ í•´ë‹¹ rolloutsì˜ batchì— ëŒ€í•œ í‰ê·  rewardë¥¼ W&Bì— ë¡œê¹…í•©ë‹ˆë‹¤. ì´ëŠ” ê´€ì°°í•˜ê¸° ìœ ìš©í•œ ì§€í‘œì…ë‹ˆë‹¤. í›ˆë ¨ì´ ì§„í–‰ë¨ì— ë”°ë¼ Agentê°€ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµí•˜ê³  ìˆë‹¤ë©´ í‰ê·  rewardê°€ 1.0ì— ê°€ê¹Œì›Œì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ìš°ë¦¬ì˜ ê³±ì…ˆ task ì˜ˆì‹œì—ì„œ, í‰ê·  reward 1.0ì€ ì—ì´ì „íŠ¸ê°€ í•´ë‹¹ ë°°ì¹˜ì—ì„œ ëª¨ë“  ë‹µì„ ì˜¬ë°”ë¥´ê²Œ ë§ì·„ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f5f7c",
   "metadata": {},
   "source": [
    "## Step 5: Monitor training with Weave and W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74040ab",
   "metadata": {},
   "source": [
    "training loopë¥¼ ì‹¤í–‰í•˜ë©´, ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§€í‘œë¥¼ ê´€ì¸¡í•˜ê¸° ìœ„í•´ Weight & Biases project pageë¡œ ì´ë™ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì€ ê° stepë³„ë¡œ ë¡œê¹…ëœ training curveë¥¼ í¬í•¨í•´ `average_reward` ì§€í‘œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì¼ ë‹¹ì‹ ì´ ARTì—ì„œ ëª¨ë¸ì˜ `project` ì™€ `name` ì„ ì œëŒ€ë¡œ ì„¤ì •í•˜ì˜€ë‹¤ë©´, ARTëŠ” ì•„ë§ˆ (loss ë˜ëŠ” policy entropyì™€ ê°™ì€) ì¶”ê°€ì ì¸ ì§€í‘œë¥¼ ìë™ìœ¼ë¡œ W&Bì— ë¡œê¹…í•  ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "\n",
    "ì´ë•Œ W&B Weaveê°€ ìœ ìš©í•©ë‹ˆë‹¤. Weaveë¥¼ ì‚¬ìš©í•˜ë©´ ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ì„ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆëŠ” interactive ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¨ìˆœíˆ reward curveë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒë¿ ì•„ë‹ˆë¼, ì§ˆë¬¸ê³¼ ë‹µë³€ ìƒ˜í”Œì„ í•¨ê»˜ í‘œì‹œí•˜ì—¬ ëª¨ë¸ ì¶œë ¥ì´ ì–´ë–»ê²Œ ê°œì„ ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” Weave íŒ¨ë„ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜, ê³±ì…ˆ ë¬¸ì œì™€ ì—ì´ì „íŠ¸ê°€ ì„œë¡œ ë‹¤ë¥¸ í•™ìŠµ ë‹¨ê³„ì—ì„œ ë‚¸ ë‹µë³€ì„ í‘œ í˜•íƒœë¡œ ë‚˜ì—´í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë©°, ì´ëŠ” ì •ì„±ì  í‰ê°€ì— ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. Weaveì˜ ê°•ì ì€ í”Œë¡¯, í…ìŠ¤íŠ¸, ì‹¬ì§€ì–´ ëª¨ë¸ ì¿¼ë¦¬ê¹Œì§€ í•œ ê³µê°„ì— ê²°í•©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ìœ¼ë¡œ, AI ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶„ì„ì„ ìœ„í•œ ìœ ì—°í•œ íˆ´í‚·ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ Weights & Biasesì—ëŠ” Models(ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë° ì•„í‹°íŒ©íŠ¸)ë¼ëŠ” ê¸°ëŠ¥ë„ ìˆìŠµë‹ˆë‹¤. í•™ìŠµì´ ëë‚˜ë©´, ì˜ˆë¥¼ ë“¤ì–´ ARTê°€ í•™ìŠµí•œ LoRA ì–´ëŒ‘í„°ì™€ ê°™ì€ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ì‹¶ì„ ê²ƒì…ë‹ˆë‹¤. W&Bë¥¼ ì‚¬ìš©í•˜ë©´ ì´ëŸ¬í•œ ê²°ê³¼ë¬¼ì„ ë²„ì €ë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394290cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, save the LoRA weights \n",
    "final_lora_dir = \"./.art/models\"  # hypothetical path where ART stored LoRA checkpoints\n",
    "# Log the fine-tuned model as a W&B artifact for versioning\n",
    "artifact = wandb.Artifact(name=\"multiplication-agent-lora\", type=\"model\")\n",
    "artifact.add_dir(final_lora_dir)\n",
    "wandb.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed7e72",
   "metadata": {},
   "source": [
    "ì•„í‹°íŒ©íŠ¸ë¥¼ ê¸°ë¡í•¨ìœ¼ë¡œì¨, í•™ìŠµëœ ì—ì´ì „íŠ¸ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ W&Bì— ì˜êµ¬ì ìœ¼ë¡œ ë³´ê´€í•  ìˆ˜ ìˆê³ , ì´í›„ì— ì´ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, ë¹„êµí•˜ê±°ë‚˜, ì‹¬ì§€ì–´ ë°°í¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. W&B Models(ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬)ëŠ” ì´ëŸ¬í•œ ì•„í‹°íŒ©íŠ¸ì™€ ê·¸ ê³„ë³´(lineage)ë¥¼ ì¶”ì í•  ìˆ˜ ìˆì–´, ì–´ë–¤ í•™ìŠµ ì‹¤í–‰(run)ì—ì„œ ì–´ë–¤ ëª¨ë¸ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ë¥¼ ëª…í™•íˆ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315388c8",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the trained agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ceda0",
   "metadata": {},
   "source": [
    "50ë²ˆì˜ stepsë¥¼ í›ˆë ¨ì‹œí‚¨ ì´í›„ë¼ë©´, ì´ì œ agentê°€ ì–¼ë§ˆë‚˜ ì˜ í•™ìŠµ ë˜ì—ˆëŠ”ì§€ test í•  ì‹œê°„ì…ë‹ˆë‹¤.\n",
    "\n",
    "`model.openai_client()`ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ ê³±ì…ˆ ë¬¸ì œì— ë‹µí•˜ê³  ì •ë‹µì¸ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ìƒì ìœ¼ë¡œëŠ” ì´ ëª¨ë¸ì´ ì²˜ìŒë³´ë‹¤ ì´ ì‘ì—…ì—ì„œ í›¨ì”¬ ë” ì•ˆì •ì ì´ë¼ëŠ” ê²ƒì„ ì•Œê²Œ ë  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "í›ˆë ¨ í›„, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´, ì•„ë˜ ëª‡ê°€ì§€ ìƒ˜í”Œ ì¿¼ë¦¬ë¥¼ ì‹œë„í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\"What is 7  8?\", \"What is 15  14?\", \"What is 3 * 19?\"]\n",
    "for q in test_questions:\n",
    "    completion = await openai_client.chat.completions.create(\n",
    "        model=model.name,\n",
    "        messages=[{\"role\": \"user\", \"content\": q}]\n",
    "    )\n",
    "    answer = completion.choices[0].message.content.strip()\n",
    "    print(f\"Q: {q} -> A: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb87449",
   "metadata": {},
   "source": [
    "í•™ìŠµì´ ì œëŒ€ë¡œ ì´ë£¨ì–´ì¡Œë‹¤ë©´, ìœ„ì˜ ì¿¼ë¦¬ì— ëŒ€í•œ ë‹µë³€ì´ ì •í™•íˆ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤(ì˜ˆ: `56, 210, 57`). ë§Œì•½ ì¼ë¶€ê°€ í‹€ë¦¬ê±°ë‚˜ ì •í™•ë„ë¥¼ ë” ë†’ì´ê³  ì‹¶ë‹¤ë©´, í•™ìŠµ ìŠ¤í…ì„ ë” ëŠ˜ë¦¬ê±°ë‚˜ ì „ëµì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì˜ˆ: ìˆ«ìì˜ ë²”ìœ„ë¥¼ ë„“íˆê±°ë‚˜ ë³´ìƒ ì²´ê³„ë¥¼ ë°”ê¾¸ëŠ” ë°©ë²•).\n",
    "\n",
    "ë‹¤ë¥¸ í™œìš© ì‚¬ë¡€: ì§€ê¸ˆ ì‚´í´ë³¸ ì˜ˆì‹œëŠ” ë§¤ìš° ë‹¨ìˆœí•˜ì§€ë§Œ, OpenPipe ARTëŠ” ë‹¤ì–‘í•œ ì—ì´ì „íŠ¸ ì‘ì—…ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜í•™ ë¬¸ì œ ëŒ€ì‹  â€œí™˜ê²½(environment)â€ì„ `ê²Œì„(ì˜ˆ: 2048, í‹±íƒí† â€”ARTë¡œ ì´ë¯¸ ì‹œì—°ëœ ë°” ìˆìŒ)`, `ì§€ì‹ ê²€ìƒ‰ ì‘ì—…(ì—ì´ì „íŠ¸ê°€ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì •ë³´ë¥¼ ì°¾ê³  ìš”ì•½)`, í˜¹ì€ `ëŒ€í™” ì›Œí¬í”Œë¡œìš°(ì—ì´ì „íŠ¸ê°€ ê¸´ ëŒ€í™” ì†ì—ì„œ ì§€ì‹œë¥¼ ë”°ë¼ì•¼ í•˜ëŠ” ê²½ìš°)`ë¡œ ì„¤ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê³¼ì •ì€ ëŒ€ë¶€ë¶„ ë™ì¼í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•´ì•¼ í•  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. ART í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•´ í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì—ì´ì „íŠ¸ì™€ ìƒí˜¸ì‘ìš©í•˜ê³ , ë§ˆì§€ë§‰ì— ë³´ìƒì„ ë¶€ì—¬í•˜ëŠ” rollout í•¨ìˆ˜ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. ì—¬ëŸ¬ ë²ˆì˜ rolloutì„ ì‹¤í–‰í•´ ARTê°€ ëª¨ë¸ì˜ ë™ì‘ì„ ìµœì í™”í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë³´ìƒ í•¨ìˆ˜ì™€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¡°ì •í•¨ìœ¼ë¡œì¨, ê²Œì„ í”Œë ˆì´ë¶€í„° ëŒ€í™” ì† ì‚¬ì‹¤ì„±ì´ë‚˜ ì•ˆì „ì„± ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ê¹Œì§€ ë‹¤ì–‘í•œ ê¸°ìˆ ì„ ì—ì´ì „íŠ¸ì—ê²Œ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ëª¨ë“  ê³¼ì •ì—ì„œ W&BëŠ” ì‹¤í—˜ ì¶”ì ì— ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ë¥¸ ë³´ìƒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ í•™ìŠµì´ ë” ë¹¨ë¼ì¡ŒëŠ”ì§€ ë¹„êµí•  ìˆ˜ ìˆê³ , ì„±ëŠ¥ì„ ì‹œê°í™”í•˜ë©°, ìµœìƒì˜ ëª¨ë¸ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. OpenPipe ARTì™€ W&Bì˜ í†µí•© ë•ë¶„ì— í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•˜ê±°ë‚˜ ì—ì´ì „íŠ¸ì˜ ë™ì‘ì„ ë””ë²„ê¹…í•  ë•Œ ë§¤ìš° í’ë¶€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f88b7a",
   "metadata": {},
   "source": [
    "## Step 7: ëª¨ë¸ ì €ì¥ ë° í—ˆê¹…í˜ì´ìŠ¤ì— ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49bbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f16551b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e68bbde",
   "metadata": {},
   "source": [
    "# ê²°ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d3f3d",
   "metadata": {},
   "source": [
    "ì´ ê¸€ì—ì„œëŠ” OpenPipe ARTë¥¼ ê¸°ì´ˆì ì¸ ëª©ì ë¶€í„° ì‹¤ì œ êµ¬í˜„ê¹Œì§€ ê¹Šì´ ìˆê²Œ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. OpenPipe ARTëŠ” ì–¸ì–´ ëª¨ë¸ ì—ì´ì „íŠ¸ì— ê°•í™”í•™ìŠµì„ ì†ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ëŠ” ì „í†µì ì¸ ê°•í™”í•™ìŠµ í”„ë ˆì„ì›Œí¬ì˜ ì—¬ëŸ¬ í•œê³„ë¥¼ í•´ê²°í•˜ëŠ”ë°, ë‹¤ì¤‘ í„´ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ì§€ì›í•˜ê³ , í´ë¼ì´ì–¸íŠ¸-ì„œë²„ ì•„í‚¤í…ì²˜ë¥¼ í†µí•œ GPU í™œìš© ê·¹ëŒ€í™”, OpenAI ìŠ¤íƒ€ì¼ì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ê¸°ì¡´ ì½”ë“œë² ì´ìŠ¤ì™€ì˜ ì†ì‰¬ìš´ í†µí•©ì´ ê·¸ ì˜ˆì…ë‹ˆë‹¤. \n",
    "ì‹¤ë¬´ìì—ê²Œ ì´ëŠ” ê³§, ì„±ëŠ¥ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ì‹¤ìˆ˜ë¥¼ ë°˜ë³µí•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë‹¨ìˆœí•œ ì •ì  íŒŒì¸íŠœë‹ì´ ì•„ë‹ˆë¼ ê²½í—˜ì„ í†µí•´ ê°œì„ í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê·¸ ê²°ê³¼ë¡œ ì‹ ë¢°ì„± í–¥ìƒ(ê³¼ê±°ì˜ ì‹¤ìˆ˜ë¥¼ íšŒí”¼), ë” ë‚˜ì€ ê³¼ì œ ìˆ˜í–‰, ë°°í¬ëœ ì‹œìŠ¤í…œì—ì„œì˜ ì§€ì† í•™ìŠµ ê°€ëŠ¥ì„±ì´ë¼ëŠ” ì´ì ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "ìš°ë¦¬ëŠ” ART í•™ìŠµ ë£¨í”„ë¥¼ ì„¤ì •í•˜ëŠ” ë°©ë²•ì„ ì‹œì—°í•˜ê³ , Weights & Biases(W&B) í†µí•©ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. W&Bì˜ Weaveì™€ Modelsë¥¼ í™œìš©í•˜ë©´ í•™ìŠµ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  í•™ìŠµëœ ëª¨ë¸ì„ ê´€ë¦¬í•  ìˆ˜ ìˆì–´, ì‹¤í—˜ ê³¼ì •ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤. ë‹¨ìˆœí•œ ê³±ì…ˆ ë¬¸ì œ í•™ìŠµ ì˜ˆì‹œëŠ” ë³µì¡í•œ ì‘ì—…ì„ ë‹¤ë£° ë•Œì˜ ì ‘ê·¼ ë°©ì‹ì„ ë‹¨ìˆœí™”í•´ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ì—ˆìœ¼ë©°, ë™ì¼í•œ ì›ë¦¬ê°€ ë³µì¡í•œ ì˜ì‚¬ê²°ì •ì´ë‚˜ ë„êµ¬ ì‚¬ìš©ê³¼ ê°™ì€ ì‘ì—…ì„ í•™ìŠµí•˜ëŠ” ë°ì—ë„ ì ìš©ë©ë‹ˆë‹¤. ì¦‰, ì‘ì—…ì„ ì •ì˜í•˜ê³ , ë³´ìƒìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µí•˜ë©°, ë‚˜ë¨¸ì§€ëŠ” ARTì— ë§¡ê¸°ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì•ìœ¼ë¡œë¥¼ ë‚´ë‹¤ë³´ë©´, OpenPipe ARTëŠ” í™œë°œíˆ ì§„í™”í•˜ê³  ìˆëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. í–¥í›„ ë°œì „ ë°©í–¥ì€ ë‹¤ìŒê³¼ ê°™ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "ê°•í™”ëœ ë³´ìƒ ëª¨ë¸ë§: í˜„ì¬ëŠ” ë³´ìƒì„ ì§ì ‘ ì •ì˜í•˜ê±°ë‚˜ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ì„ ì‚¬ìš©í•˜ì§€ë§Œ, ì•ìœ¼ë¡œëŠ” í•™ìŠµëœ ë³´ìƒ ëª¨ë¸ì´ë‚˜ ì¸ê°„ í”¼ë“œë°±(RLHFì™€ ìœ ì‚¬)ì„ ì§ì ‘ í™œìš©í•˜ëŠ” ê³ ê¸‰ ê¸°ë²•ì´ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ARTëŠ” ì´ë¯¸ RULERë¼ëŠ” ê¸°ëŠ¥ì„ ë„ì…í•´ LLMì„ íŒì •ìë¡œ í™œìš©, ê²½ë¡œë¥¼ ì ìˆ˜í™”í•˜ê³  ìˆ˜ì‘ì—… ë³´ìƒ í•¨ìˆ˜ì˜ í•„ìš”ì„±ì„ í¬ê²Œ ì¤„ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì€ ì—ì´ì „íŠ¸ì˜ â€œì„±ê³µâ€ ê¸°ì¤€ ì •ì˜ë¥¼ ë” ì‰½ê²Œ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë” í­ë„“ì€ ëª¨ë¸ ì§€ì›ê³¼ í™•ì¥ì„±: ëŒ€ê·œëª¨ ë° íŠ¹ìˆ˜í™” ëª¨ë¸ì´ ë“±ì¥í•¨ì— ë”°ë¼ ARTëŠ” ì´ë¥¼ ì§€ì›í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í™•ì¥ë  ê²ƒì…ë‹ˆë‹¤. í”„ëŸ°íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œì˜ ë¶„ë¦¬ ë•ë¶„ì— ë¶„ì‚° í•™ìŠµì´ë‚˜ ëŒ€ê·œëª¨ ëª¨ë¸ì˜ í•˜ë“œì›¨ì–´ ìƒ¤ë”©ê¹Œì§€ ê°€ëŠ¥ì„±ì´ ì—´ë ¤ ìˆìœ¼ë©°, ìƒˆë¡œìš´ í•˜ë“œì›¨ì–´ ìµœì í™”ë‚˜ GRPO ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„± ê°œì„ ë„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í”„ë¡œë•ì…˜ í†µí•©: í˜„ì¬ ARTëŠ” ì—°êµ¬ ë° í”„ë¡œí† íƒ€ì´í•‘ì— ì í•©í•˜ì§€ë§Œ, ì¥ê¸°ì ìœ¼ë¡œëŠ” ì‹¤ì œ ì„œë¹„ìŠ¤ì— í†µí•©ë  ë„êµ¬ë“¤ì´ ë“±ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‹¤ì œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ í•™ìŠµí•˜ì—¬(ì ì ˆí•œ ì•ˆì „ì¥ì¹˜ì™€ í•¨ê»˜) ë°°í¬ëœ ì—ì´ì „íŠ¸ê°€ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ë¯¸ë˜ì—ëŠ” ì´ëŸ¬í•œ ì§€ì† í•™ìŠµì„ ì•ˆì „í•˜ê³  ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ ì¶”ê°€ë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬ì™€ ìƒíƒœê³„: ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì¸ ë§Œí¼, ARTì˜ ë°œì „ì€ ì‚¬ìš©ì ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ì—¬ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. LangChain ê°™ì€ ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ì˜ í†µí•©, ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ë¼ì´ë¸ŒëŸ¬ë¦¬, ë” ë§ì€ ì˜ˆì œë“¤ì´ ìƒê²¨ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ W&B ìƒíƒœê³„ì™€ì˜ ê²°í•©ì„ í†µí•´ ê³µê°œ ëŒ€ì‹œë³´ë“œ, ë¦¬í¬íŠ¸, ëª¨ë²” ì‚¬ë¡€ ê³µìœ  ë“±ì´ í™œë°œíˆ ì´ë£¨ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "OpenPipe ARTëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ AI ì—ì´ì „íŠ¸ì— ê°•í™”í•™ìŠµì„ ì‹¤ìš©ì ìœ¼ë¡œ ì ìš©í•˜ëŠ” ë° ìˆì–´ ì¤‘ìš”í•œ ì§„ì „ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê°œë°œìë“¤ì€ ì •ì ì¸ ëª¨ë¸ ì„±ëŠ¥ì„ ë„˜ì–´, ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•œ ì§€ì†ì ì¸ í–‰ë™ ê°œì„ ì„ ê°€ëŠ¥í•˜ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ììœ¨ ì—ì´ì „íŠ¸ë‚˜ ë³µì¡í•œ ì±—ë´‡ì„ ë§Œë“¤ê³  ìˆëŠ”ë° ê¸°ëŒ€ë§Œí¼ ê°•ê±´í•˜ê±°ë‚˜ ì •í™•í•˜ì§€ ì•Šë‹¤ë©´, ARTë¥¼ ê³ ë ¤í•´ë³´ì‹­ì‹œì˜¤. ìµœì†Œí•œì˜ ìˆ˜ì •ë§Œìœ¼ë¡œ ì—ì´ì „íŠ¸ì— í•™ìŠµ ë£¨í”„ë¥¼ ë‚´ì¥í•  ìˆ˜ ìˆê³ , ì ì°¨ ê°œì„ ë˜ëŠ” ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ W&B ê°™ì€ ë„êµ¬ë¡œ í•™ìŠµ ê³¼ì •ì„ ì¶”ì í•˜ë©´, í•™ìŠµ ê³¼ì •ì„ ì™„ì „íˆ íˆ¬ëª…í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "OpenPipe ARTì˜ ë¯¸ë˜ëŠ” ë§¤ìš° ë°ìŠµë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ ê°œë°œ, ì„±ì¥í•˜ëŠ” ì‚¬ìš©ì ì»¤ë®¤ë‹ˆí‹°, MLOps ë„êµ¬ì™€ì˜ í†µí•©ì´ ë§ë¬¼ë ¤, ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì•ìœ¼ë¡œ í‘œì¤€ì ì¸ ì—ì´ì „íŠ¸ í•™ìŠµ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ìë¦¬ ì¡ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ììœ¨ì ì¸ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ê°€ í•  ìˆ˜ ìˆëŠ” ì¼ì˜ ë²”ìœ„ë¥¼ ê³„ì†í•´ì„œ í™•ì¥ì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì¦ê±°ìš´ í•™ìŠµ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤! ë” ê¹Šì´ íƒêµ¬í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´, ê´€ë ¨ ì˜ˆì œë¥¼ í™•ì¸í•˜ê³  OpenPipe ì»¤ë®¤ë‹ˆí‹°ì— ì°¸ì—¬í•´ ë³´ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤. ê²Œì„ í”Œë ˆì´ ì—ì´ì „íŠ¸ë“ , ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ í†µí•´ í•™ìŠµí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë“ , OpenPipe ARTì™€ W&BëŠ” ë” ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ë° í•„ìš”í•œ í”¼ë“œë°± ë£¨í”„ë¥¼ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc2e2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
